<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ad0000; } /* Alert */
code span.an { color: #5e5e5e; } /* Annotation */
code span.at { color: #20794d; } /* Attribute */
code span.bn { color: #ad0000; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007ba5; } /* ControlFlow */
code span.ch { color: #20794d; } /* Char */
code span.cn { color: #8f5902; } /* Constant */
code span.co { color: #5e5e5e; } /* Comment */
code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
code span.dt { color: #ad0000; } /* DataType */
code span.dv { color: #ad0000; } /* DecVal */
code span.er { color: #ad0000; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #ad0000; } /* Float */
code span.fu { color: #4758ab; } /* Function */
code span.im { } /* Import */
code span.in { color: #5e5e5e; } /* Information */
code span.kw { color: #007ba5; } /* Keyword */
code span.op { color: #5e5e5e; } /* Operator */
code span.ot { color: #007ba5; } /* Other */
code span.pp { color: #ad0000; } /* Preprocessor */
code span.sc { color: #20794d; } /* SpecialChar */
code span.ss { color: #20794d; } /* SpecialString */
code span.st { color: #20794d; } /* String */
code span.va { color: #111111; } /* Variable */
code span.vs { color: #20794d; } /* VerbatimString */
code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
</style>

  <!--radix_placeholder_meta_tags-->
  <title>GLMM FAQ</title>

  <meta property="description" itemprop="description" content="an informal GLMM FAQ list for the r-sig-mixed-models mailing list"/>


  <!--  https://schema.org/Article -->
  <meta property="article:published" itemprop="datePublished" content="2021-04-28"/>
  <meta property="article:created" itemprop="dateCreated" content="2021-04-28"/>
  <meta name="article:author" content="Ben Bolker"/>

  <!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
  <meta property="og:title" content="GLMM FAQ"/>
  <meta property="og:type" content="article"/>
  <meta property="og:description" content="an informal GLMM FAQ list for the r-sig-mixed-models mailing list"/>
  <meta property="og:locale" content="en_US"/>

  <!--  https://dev.twitter.com/cards/types/summary -->
  <meta property="twitter:card" content="summary"/>
  <meta property="twitter:title" content="GLMM FAQ"/>
  <meta property="twitter:description" content="an informal GLMM FAQ list for the r-sig-mixed-models mailing list"/>

  <!--/radix_placeholder_meta_tags-->
  <!--radix_placeholder_rmarkdown_metadata-->

  <script type="text/json" id="radix-rmarkdown-metadata">
  {"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","description","author","date","output","categories"]}},"value":[{"type":"character","attributes":{},"value":["GLMM FAQ"]},{"type":"character","attributes":{},"value":["an informal GLMM FAQ list for the r-sig-mixed-models mailing list\n"]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","url"]}},"value":[{"type":"character","attributes":{},"value":["Ben Bolker"]},{"type":"character","attributes":{},"value":["https://github.com/Bokola"]}]}]},{"type":"character","attributes":{},"value":["04-28-2021"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["distill::distill_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained"]}},"value":[{"type":"logical","attributes":{},"value":[false]}]}]},{"type":"character","attributes":{},"value":["GLMM","poisson","log link","logit","probit"]}]}
  </script>
  <!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["glmm-faq_files/anchor-4.2.2/anchor.min.js","glmm-faq_files/bowser-1.9.3/bowser.min.js","glmm-faq_files/distill-2.2.21/template.v2.js","glmm-faq_files/figure-html5/ggplot-1.png","glmm-faq_files/figure-html5/lme4pred-1.png","glmm-faq_files/figure-html5/lme4pred-2.png","glmm-faq_files/figure-html5/lmepred-1.png","glmm-faq_files/figure-html5/lmepred-2.png","glmm-faq_files/figure-html5/lmepred-3.png","glmm-faq_files/header-attrs-2.7/header-attrs.js","glmm-faq_files/jquery-1.11.3/jquery.min.js","glmm-faq_files/popper-2.6.0/popper.min.js","glmm-faq_files/tippy-6.2.7/tippy-bundle.umd.min.js","glmm-faq_files/tippy-6.2.7/tippy-light-border.css","glmm-faq_files/tippy-6.2.7/tippy.css","glmm-faq_files/tippy-6.2.7/tippy.umd.min.js","glmm-faq_files/webcomponents-2.0.0/webcomponents.js"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->
  <!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->

  <style type="text/css">

  body {
    background-color: white;
  }

  .pandoc-table {
    width: 100%;
  }

  .pandoc-table>caption {
    margin-bottom: 10px;
  }

  .pandoc-table th:not([align]) {
    text-align: left;
  }

  .pagedtable-footer {
    font-size: 15px;
  }

  d-byline .byline {
    grid-template-columns: 2fr 2fr;
  }

  d-byline .byline h3 {
    margin-block-start: 1.5em;
  }

  d-byline .byline .authors-affiliations h3 {
    margin-block-start: 0.5em;
  }

  .authors-affiliations .orcid-id {
    width: 16px;
    height:16px;
    margin-left: 4px;
    margin-right: 4px;
    vertical-align: middle;
    padding-bottom: 2px;
  }

  d-title .dt-tags {
    margin-top: 1em;
    grid-column: text;
  }

  .dt-tags .dt-tag {
    text-decoration: none;
    display: inline-block;
    color: rgba(0,0,0,0.6);
    padding: 0em 0.4em;
    margin-right: 0.5em;
    margin-bottom: 0.4em;
    font-size: 70%;
    border: 1px solid rgba(0,0,0,0.2);
    border-radius: 3px;
    text-transform: uppercase;
    font-weight: 500;
  }

  d-article table.gt_table td,
  d-article table.gt_table th {
    border-bottom: none;
  }

  .html-widget {
    margin-bottom: 2.0em;
  }

  .l-screen-inset {
    padding-right: 16px;
  }

  .l-screen .caption {
    margin-left: 10px;
  }

  .shaded {
    background: rgb(247, 247, 247);
    padding-top: 20px;
    padding-bottom: 20px;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  }

  .shaded .html-widget {
    margin-bottom: 0;
    border: 1px solid rgba(0, 0, 0, 0.1);
  }

  .shaded .shaded-content {
    background: white;
  }

  .text-output {
    margin-top: 0;
    line-height: 1.5em;
  }

  .hidden {
    display: none !important;
  }

  d-article {
    padding-top: 2.5rem;
    padding-bottom: 30px;
  }

  d-appendix {
    padding-top: 30px;
  }

  d-article>p>img {
    width: 100%;
  }

  d-article h2 {
    margin: 1rem 0 1.5rem 0;
  }

  d-article h3 {
    margin-top: 1.5rem;
  }

  d-article iframe {
    border: 1px solid rgba(0, 0, 0, 0.1);
    margin-bottom: 2.0em;
    width: 100%;
  }

  /* Tweak code blocks */

  d-article div.sourceCode code,
  d-article pre code {
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  }

  d-article pre,
  d-article div.sourceCode,
  d-article div.sourceCode pre {
    overflow: auto;
  }

  d-article div.sourceCode {
    background-color: white;
  }

  d-article div.sourceCode pre {
    padding-left: 10px;
    font-size: 12px;
    border-left: 2px solid rgba(0,0,0,0.1);
  }

  d-article pre {
    font-size: 12px;
    color: black;
    background: none;
    margin-top: 0;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;

    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;

    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }

  d-article pre a {
    border-bottom: none;
  }

  d-article pre a:hover {
    border-bottom: none;
    text-decoration: underline;
  }

  d-article details {
    grid-column: text;
    margin-bottom: 0.8em;
  }

  @media(min-width: 768px) {

  d-article pre,
  d-article div.sourceCode,
  d-article div.sourceCode pre {
    overflow: visible !important;
  }

  d-article div.sourceCode pre {
    padding-left: 18px;
    font-size: 14px;
  }

  d-article pre {
    font-size: 14px;
  }

  }

  figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }

  /* CSS for d-contents */

  .d-contents {
    grid-column: text;
    color: rgba(0,0,0,0.8);
    font-size: 0.9em;
    padding-bottom: 1em;
    margin-bottom: 1em;
    padding-bottom: 0.5em;
    margin-bottom: 1em;
    padding-left: 0.25em;
    justify-self: start;
  }

  @media(min-width: 1000px) {
    .d-contents.d-contents-float {
      height: 0;
      grid-column-start: 1;
      grid-column-end: 4;
      justify-self: center;
      padding-right: 3em;
      padding-left: 2em;
    }
  }

  .d-contents nav h3 {
    font-size: 18px;
    margin-top: 0;
    margin-bottom: 1em;
  }

  .d-contents li {
    list-style-type: none
  }

  .d-contents nav > ul {
    padding-left: 0;
  }

  .d-contents ul {
    padding-left: 1em
  }

  .d-contents nav ul li {
    margin-top: 0.6em;
    margin-bottom: 0.2em;
  }

  .d-contents nav a {
    font-size: 13px;
    border-bottom: none;
    text-decoration: none
    color: rgba(0, 0, 0, 0.8);
  }

  .d-contents nav a:hover {
    text-decoration: underline solid rgba(0, 0, 0, 0.6)
  }

  .d-contents nav > ul > li > a {
    font-weight: 600;
  }

  .d-contents nav > ul > li > ul {
    font-weight: inherit;
  }

  .d-contents nav > ul > li > ul > li {
    margin-top: 0.2em;
  }


  .d-contents nav ul {
    margin-top: 0;
    margin-bottom: 0.25em;
  }

  .d-article-with-toc h2:nth-child(2) {
    margin-top: 0;
  }


  /* Figure */

  .figure {
    position: relative;
    margin-bottom: 2.5em;
    margin-top: 1.5em;
  }

  .figure img {
    width: 100%;
  }

  .figure .caption {
    color: rgba(0, 0, 0, 0.6);
    font-size: 12px;
    line-height: 1.5em;
  }

  .figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }

  .figure .caption a {
    color: rgba(0, 0, 0, 0.6);
  }

  .figure .caption b,
  .figure .caption strong, {
    font-weight: 600;
    color: rgba(0, 0, 0, 1.0);
  }

  /* Citations */

  d-article .citation {
    color: inherit;
    cursor: inherit;
  }

  div.hanging-indent{
    margin-left: 1em; text-indent: -1em;
  }

  /* Citation hover box */

  .tippy-box[data-theme~=light-border] {
    background-color: rgba(250, 250, 250, 0.95);
  }

  .tippy-content > p {
    margin-bottom: 0;
    padding: 2px;
  }


  /* Tweak 1000px media break to show more text */

  @media(min-width: 1000px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 16px;
    }

    .grid {
      grid-column-gap: 16px;
    }

    d-article {
      font-size: 1.06rem;
      line-height: 1.7em;
    }
    figure .caption, .figure .caption, figure figcaption {
      font-size: 13px;
    }
  }

  @media(min-width: 1180px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 32px;
    }

    .grid {
      grid-column-gap: 32px;
    }
  }


  /* Get the citation styles for the appendix (not auto-injected on render since
     we do our own rendering of the citation appendix) */

  d-appendix .citation-appendix,
  .d-appendix .citation-appendix {
    font-size: 11px;
    line-height: 15px;
    border-left: 1px solid rgba(0, 0, 0, 0.1);
    padding-left: 18px;
    border: 1px solid rgba(0,0,0,0.1);
    background: rgba(0, 0, 0, 0.02);
    padding: 10px 18px;
    border-radius: 3px;
    color: rgba(150, 150, 150, 1);
    overflow: hidden;
    margin-top: -12px;
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  /* Include appendix styles here so they can be overridden */

  d-appendix {
    contain: layout style;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-top: 60px;
    margin-bottom: 0;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    color: rgba(0,0,0,0.5);
    padding-top: 60px;
    padding-bottom: 48px;
  }

  d-appendix h3 {
    grid-column: page-start / text-start;
    font-size: 15px;
    font-weight: 500;
    margin-top: 1em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.65);
  }

  d-appendix h3 + * {
    margin-top: 1em;
  }

  d-appendix ol {
    padding: 0 0 0 15px;
  }

  @media (min-width: 768px) {
    d-appendix ol {
      padding: 0 0 0 30px;
      margin-left: -30px;
    }
  }

  d-appendix li {
    margin-bottom: 1em;
  }

  d-appendix a {
    color: rgba(0, 0, 0, 0.6);
  }

  d-appendix > * {
    grid-column: text;
  }

  d-appendix > d-footnote-list,
  d-appendix > d-citation-list,
  d-appendix > distill-appendix {
    grid-column: screen;
  }

  /* Include footnote styles here so they can be overridden */

  d-footnote-list {
    contain: layout style;
  }

  d-footnote-list > * {
    grid-column: text;
  }

  d-footnote-list a.footnote-backlink {
    color: rgba(0,0,0,0.3);
    padding-left: 0.5em;
  }



  /* Anchor.js */

  .anchorjs-link {
    /*transition: all .25s linear; */
    text-decoration: none;
    border-bottom: none;
  }
  *:hover > .anchorjs-link {
    margin-left: -1.125em !important;
    text-decoration: none;
    border-bottom: none;
  }

  /* Social footer */

  .social_footer {
    margin-top: 30px;
    margin-bottom: 0;
    color: rgba(0,0,0,0.67);
  }

  .disqus-comments {
    margin-right: 30px;
  }

  .disqus-comment-count {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
    cursor: pointer;
  }

  #disqus_thread {
    margin-top: 30px;
  }

  .article-sharing a {
    border-bottom: none;
    margin-right: 8px;
  }

  .article-sharing a:hover {
    border-bottom: none;
  }

  .sidebar-section.subscribe {
    font-size: 12px;
    line-height: 1.6em;
  }

  .subscribe p {
    margin-bottom: 0.5em;
  }


  .article-footer .subscribe {
    font-size: 15px;
    margin-top: 45px;
  }


  .sidebar-section.custom {
    font-size: 12px;
    line-height: 1.6em;
  }

  .custom p {
    margin-bottom: 0.5em;
  }

  /* Styles for listing layout (hide title) */
  .layout-listing d-title, .layout-listing .d-title {
    display: none;
  }

  /* Styles for posts lists (not auto-injected) */


  .posts-with-sidebar {
    padding-left: 45px;
    padding-right: 45px;
  }

  .posts-list .description h2,
  .posts-list .description p {
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  }

  .posts-list .description h2 {
    font-weight: 700;
    border-bottom: none;
    padding-bottom: 0;
  }

  .posts-list h2.post-tag {
    border-bottom: 1px solid rgba(0, 0, 0, 0.2);
    padding-bottom: 12px;
  }
  .posts-list {
    margin-top: 60px;
    margin-bottom: 24px;
  }

  .posts-list .post-preview {
    text-decoration: none;
    overflow: hidden;
    display: block;
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
    padding: 24px 0;
  }

  .post-preview-last {
    border-bottom: none !important;
  }

  .posts-list .posts-list-caption {
    grid-column: screen;
    font-weight: 400;
  }

  .posts-list .post-preview h2 {
    margin: 0 0 6px 0;
    line-height: 1.2em;
    font-style: normal;
    font-size: 24px;
  }

  .posts-list .post-preview p {
    margin: 0 0 12px 0;
    line-height: 1.4em;
    font-size: 16px;
  }

  .posts-list .post-preview .thumbnail {
    box-sizing: border-box;
    margin-bottom: 24px;
    position: relative;
    max-width: 500px;
  }
  .posts-list .post-preview img {
    width: 100%;
    display: block;
  }

  .posts-list .metadata {
    font-size: 12px;
    line-height: 1.4em;
    margin-bottom: 18px;
  }

  .posts-list .metadata > * {
    display: inline-block;
  }

  .posts-list .metadata .publishedDate {
    margin-right: 2em;
  }

  .posts-list .metadata .dt-authors {
    display: block;
    margin-top: 0.3em;
    margin-right: 2em;
  }

  .posts-list .dt-tags {
    display: block;
    line-height: 1em;
  }

  .posts-list .dt-tags .dt-tag {
    display: inline-block;
    color: rgba(0,0,0,0.6);
    padding: 0.3em 0.4em;
    margin-right: 0.2em;
    margin-bottom: 0.4em;
    font-size: 60%;
    border: 1px solid rgba(0,0,0,0.2);
    border-radius: 3px;
    text-transform: uppercase;
    font-weight: 500;
  }

  .posts-list img {
    opacity: 1;
  }

  .posts-list img[data-src] {
    opacity: 0;
  }

  .posts-more {
    clear: both;
  }


  .posts-sidebar {
    font-size: 16px;
  }

  .posts-sidebar h3 {
    font-size: 16px;
    margin-top: 0;
    margin-bottom: 0.5em;
    font-weight: 400;
    text-transform: uppercase;
  }

  .sidebar-section {
    margin-bottom: 30px;
  }

  .categories ul {
    list-style-type: none;
    margin: 0;
    padding: 0;
  }

  .categories li {
    color: rgba(0, 0, 0, 0.8);
    margin-bottom: 0;
  }

  .categories li>a {
    border-bottom: none;
  }

  .categories li>a:hover {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
  }

  .categories .active {
    font-weight: 600;
  }

  .categories .category-count {
    color: rgba(0, 0, 0, 0.4);
  }


  @media(min-width: 768px) {
    .posts-list .post-preview h2 {
      font-size: 26px;
    }
    .posts-list .post-preview .thumbnail {
      float: right;
      width: 30%;
      margin-bottom: 0;
    }
    .posts-list .post-preview .description {
      float: left;
      width: 45%;
    }
    .posts-list .post-preview .metadata {
      float: left;
      width: 20%;
      margin-top: 8px;
    }
    .posts-list .post-preview p {
      margin: 0 0 12px 0;
      line-height: 1.5em;
      font-size: 16px;
    }
    .posts-with-sidebar .posts-list {
      float: left;
      width: 75%;
    }
    .posts-with-sidebar .posts-sidebar {
      float: right;
      width: 20%;
      margin-top: 60px;
      padding-top: 24px;
      padding-bottom: 24px;
    }
  }


  /* Improve display for browsers without grid (IE/Edge <= 15) */

  .downlevel {
    line-height: 1.6em;
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
    margin: 0;
  }

  .downlevel .d-title {
    padding-top: 6rem;
    padding-bottom: 1.5rem;
  }

  .downlevel .d-title h1 {
    font-size: 50px;
    font-weight: 700;
    line-height: 1.1em;
    margin: 0 0 0.5rem;
  }

  .downlevel .d-title p {
    font-weight: 300;
    font-size: 1.2rem;
    line-height: 1.55em;
    margin-top: 0;
  }

  .downlevel .d-byline {
    padding-top: 0.8em;
    padding-bottom: 0.8em;
    font-size: 0.8rem;
    line-height: 1.8em;
  }

  .downlevel .section-separator {
    border: none;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
  }

  .downlevel .d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
    padding-top: 1rem;
    padding-bottom: 2rem;
  }


  .downlevel .d-appendix {
    padding-left: 0;
    padding-right: 0;
    max-width: none;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.5);
    padding-top: 40px;
    padding-bottom: 48px;
  }

  .downlevel .footnotes ol {
    padding-left: 13px;
  }

  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
    padding-left: 40px;
    padding-right: 40px;
  }

  @media(min-width: 768px) {
    .downlevel .base-grid,
    .downlevel .distill-header,
    .downlevel .d-title,
    .downlevel .d-abstract,
    .downlevel .d-article,
    .downlevel .d-appendix,
    .downlevel .distill-appendix,
    .downlevel .d-byline,
    .downlevel .d-footnote-list,
    .downlevel .d-citation-list,
    .downlevel .distill-footer,
    .downlevel .appendix-bottom,
    .downlevel .posts-container {
    padding-left: 150px;
    padding-right: 150px;
    max-width: 900px;
  }
  }

  .downlevel pre code {
    display: block;
    border-left: 2px solid rgba(0, 0, 0, .1);
    padding: 0 0 0 20px;
    font-size: 14px;
  }

  .downlevel code, .downlevel pre {
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;

    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;

    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }

  .downlevel .posts-list .post-preview {
    color: inherit;
  }



  </style>

  <script type="application/javascript">

  function is_downlevel_browser() {
    if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                   window.navigator.userAgent)) {
      return true;
    } else {
      return window.load_distill_framework === undefined;
    }
  }

  // show body when load is complete
  function on_load_complete() {

    // add anchors
    if (window.anchors) {
      window.anchors.options.placement = 'left';
      window.anchors.add('d-article > h2, d-article > h3, d-article > h4, d-article > h5');
    }


    // set body to visible
    document.body.style.visibility = 'visible';

    // force redraw for leaflet widgets
    if (window.HTMLWidgets) {
      var maps = window.HTMLWidgets.findAll(".leaflet");
      $.each(maps, function(i, el) {
        var map = this.getMap();
        map.invalidateSize();
        map.eachLayer(function(layer) {
          if (layer instanceof L.TileLayer)
            layer.redraw();
        });
      });
    }

    // trigger 'shown' so htmlwidgets resize
    $('d-article').trigger('shown');
  }

  function init_distill() {

    init_common();

    // create front matter
    var front_matter = $('<d-front-matter></d-front-matter>');
    $('#distill-front-matter').wrap(front_matter);

    // create d-title
    $('.d-title').changeElementType('d-title');

    // create d-byline
    var byline = $('<d-byline></d-byline>');
    $('.d-byline').replaceWith(byline);

    // create d-article
    var article = $('<d-article></d-article>');
    $('.d-article').wrap(article).children().unwrap();

    // move posts container into article
    $('.posts-container').appendTo($('d-article'));

    // create d-appendix
    $('.d-appendix').changeElementType('d-appendix');

    // flag indicating that we have appendix items
    var appendix = $('.appendix-bottom').children('h3').length > 0;

    // replace footnotes with <d-footnote>
    $('.footnote-ref').each(function(i, val) {
      appendix = true;
      var href = $(this).attr('href');
      var id = href.replace('#', '');
      var fn = $('#' + id);
      var fn_p = $('#' + id + '>p');
      fn_p.find('.footnote-back').remove();
      var text = fn_p.html();
      var dtfn = $('<d-footnote></d-footnote>');
      dtfn.html(text);
      $(this).replaceWith(dtfn);
    });
    // remove footnotes
    $('.footnotes').remove();

    // move refs into #references-listing
    $('#references-listing').replaceWith($('#refs'));

    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      var id = $(this).attr('id');
      $('.d-contents a[href="#' + id + '"]').parent().remove();
      appendix = true;
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
    });

    // show d-appendix if we have appendix content
    $("d-appendix").css('display', appendix ? 'grid' : 'none');

    // localize layout chunks to just output
    $('.layout-chunk').each(function(i, val) {

      // capture layout
      var layout = $(this).attr('data-layout');

      // apply layout to markdown level block elements
      var elements = $(this).children().not('details, div.sourceCode, pre, script');
      elements.each(function(i, el) {
        var layout_div = $('<div class="' + layout + '"></div>');
        if (layout_div.hasClass('shaded')) {
          var shaded_content = $('<div class="shaded-content"></div>');
          $(this).wrap(shaded_content);
          $(this).parent().wrap(layout_div);
        } else {
          $(this).wrap(layout_div);
        }
      });


      // unwrap the layout-chunk div
      $(this).children().unwrap();
    });

    // remove code block used to force  highlighting css
    $('.distill-force-highlighting-css').parent().remove();

    // remove empty line numbers inserted by pandoc when using a
    // custom syntax highlighting theme
    $('code.sourceCode a:empty').remove();

    // load distill framework
    load_distill_framework();

    // wait for window.distillRunlevel == 4 to do post processing
    function distill_post_process() {

      if (!window.distillRunlevel || window.distillRunlevel < 4)
        return;

      // hide author/affiliations entirely if we have no authors
      var front_matter = JSON.parse($("#distill-front-matter").html());
      var have_authors = front_matter.authors && front_matter.authors.length > 0;
      if (!have_authors)
        $('d-byline').addClass('hidden');

      // article with toc class
      $('.d-contents').parent().addClass('d-article-with-toc');

      // strip links that point to #
      $('.authors-affiliations').find('a[href="#"]').removeAttr('href');

      // add orcid ids
      $('.authors-affiliations').find('.author').each(function(i, el) {
        var orcid_id = front_matter.authors[i].orcidID;
        if (orcid_id) {
          var a = $('<a></a>');
          a.attr('href', 'https://orcid.org/' + orcid_id);
          var img = $('<img></img>');
          img.addClass('orcid-id');
          img.attr('alt', 'ORCID ID');
          img.attr('src','data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==');
          a.append(img);
          $(this).append(a);
        }
      });

      // hide elements of author/affiliations grid that have no value
      function hide_byline_column(caption) {
        $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
      }

      // affiliations
      var have_affiliations = false;
      for (var i = 0; i<front_matter.authors.length; ++i) {
        var author = front_matter.authors[i];
        if (author.affiliation !== "&nbsp;") {
          have_affiliations = true;
          break;
        }
      }
      if (!have_affiliations)
        $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');

      // published date
      if (!front_matter.publishedDate)
        hide_byline_column("Published");

      // document object identifier
      var doi = $('d-byline').find('h3:contains("DOI")');
      var doi_p = doi.next().empty();
      if (!front_matter.doi) {
        // if we have a citation and valid citationText then link to that
        if ($('#citation').length > 0 && front_matter.citationText) {
          doi.html('Citation');
          $('<a href="#citation"></a>')
            .text(front_matter.citationText)
            .appendTo(doi_p);
        } else {
          hide_byline_column("DOI");
        }
      } else {
        $('<a></a>')
           .attr('href', "https://doi.org/" + front_matter.doi)
           .html(front_matter.doi)
           .appendTo(doi_p);
      }

       // change plural form of authors/affiliations
      if (front_matter.authors.length === 1) {
        var grid = $('.authors-affiliations');
        grid.children('h3:contains("Authors")').text('Author');
        grid.children('h3:contains("Affiliations")').text('Affiliation');
      }

      // remove d-appendix and d-footnote-list local styles
      $('d-appendix > style:first-child').remove();
      $('d-footnote-list > style:first-child').remove();

      // move appendix-bottom entries to the bottom
      $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
      $('.appendix-bottom').remove();

      // hoverable references
      $('span.citation[data-cites]').each(function() {
        var refHtml = $('#ref-' + $(this).attr('data-cites')).html();
        window.tippy(this, {
          allowHTML: true,
          content: refHtml,
          maxWidth: 500,
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start'
        });
      });

      // clear polling timer
      clearInterval(tid);

      // show body now that everything is ready
      on_load_complete();
    }

    var tid = setInterval(distill_post_process, 50);
    distill_post_process();

  }

  function init_downlevel() {

    init_common();

     // insert hr after d-title
    $('.d-title').after($('<hr class="section-separator"/>'));

    // check if we have authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;

    // manage byline/border
    if (!have_authors)
      $('.d-byline').remove();
    $('.d-byline').after($('<hr class="section-separator"/>'));
    $('.d-byline a').remove();

    // remove toc
    $('.d-contents').remove();

    // move appendix elements
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
    });


    // inject headers into references and footnotes
    var refs_header = $('<h3></h3>');
    refs_header.text('References');
    $('#refs').prepend(refs_header);

    var footnotes_header = $('<h3></h3');
    footnotes_header.text('Footnotes');
    $('.footnotes').children('hr').first().replaceWith(footnotes_header);

    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
    $('.appendix-bottom').remove();

    // remove appendix if it's empty
    if ($('.d-appendix').children().length === 0)
      $('.d-appendix').remove();

    // prepend separator above appendix
    $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));

    // trim code
    $('pre>code').each(function(i, val) {
      $(this).html($.trim($(this).html()));
    });

    // move posts-container right before article
    $('.posts-container').insertBefore($('.d-article'));

    $('body').addClass('downlevel');

    on_load_complete();
  }


  function init_common() {

    // jquery plugin to change element types
    (function($) {
      $.fn.changeElementType = function(newType) {
        var attrs = {};

        $.each(this[0].attributes, function(idx, attr) {
          attrs[attr.nodeName] = attr.nodeValue;
        });

        this.replaceWith(function() {
          return $("<" + newType + "/>", attrs).append($(this).contents());
        });
      };
    })(jQuery);

    // prevent underline for linked images
    $('a > img').parent().css({'border-bottom' : 'none'});

    // mark non-body figures created by knitr chunks as 100% width
    $('.layout-chunk').each(function(i, val) {
      var figures = $(this).find('img, .html-widget');
      if ($(this).attr('data-layout') !== "l-body") {
        figures.css('width', '100%');
      } else {
        figures.css('max-width', '100%');
        figures.filter("[width]").each(function(i, val) {
          var fig = $(this);
          fig.css('width', fig.attr('width') + 'px');
        });

      }
    });

    // auto-append index.html to post-preview links in file: protocol
    // and in rstudio ide preview
    $('.post-preview').each(function(i, val) {
      if (window.location.protocol === "file:")
        $(this).attr('href', $(this).attr('href') + "index.html");
    });

    // get rid of index.html references in header
    if (window.location.protocol !== "file:") {
      $('.distill-site-header a[href]').each(function(i,val) {
        $(this).attr('href', $(this).attr('href').replace("index.html", "./"));
      });
    }

    // add class to pandoc style tables
    $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
    $('.kable-table').children('table').addClass('pandoc-table');

    // add figcaption style to table captions
    $('caption').parent('table').addClass("figcaption");

    // initialize posts list
    if (window.init_posts_list)
      window.init_posts_list();

    // implmement disqus comment link
    $('.disqus-comment-count').click(function() {
      window.headroom_prevent_pin = true;
      $('#disqus_thread').toggleClass('hidden');
      if (!$('#disqus_thread').hasClass('hidden')) {
        var offset = $(this).offset();
        $(window).resize();
        $('html, body').animate({
          scrollTop: offset.top - 35
        });
      }
    });
  }

  document.addEventListener('DOMContentLoaded', function() {
    if (is_downlevel_browser())
      init_downlevel();
    else
      window.addEventListener('WebComponentsReady', init_distill);
  });

  </script>

  <!--/radix_placeholder_distill-->
  <script src="glmm-faq_files/header-attrs-2.7/header-attrs.js"></script>
  <script src="glmm-faq_files/jquery-1.11.3/jquery.min.js"></script>
  <script src="glmm-faq_files/popper-2.6.0/popper.min.js"></script>
  <link href="glmm-faq_files/tippy-6.2.7/tippy.css" rel="stylesheet" />
  <link href="glmm-faq_files/tippy-6.2.7/tippy-light-border.css" rel="stylesheet" />
  <script src="glmm-faq_files/tippy-6.2.7/tippy.umd.min.js"></script>
  <script src="glmm-faq_files/anchor-4.2.2/anchor.min.js"></script>
  <script src="glmm-faq_files/bowser-1.9.3/bowser.min.js"></script>
  <script src="glmm-faq_files/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="glmm-faq_files/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
  <!--/radix_placeholder_site_in_header-->


</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"GLMM FAQ","description":"an informal GLMM FAQ list for the r-sig-mixed-models mailing list","authors":[{"author":"Ben Bolker","authorURL":"https://github.com/Bokola","affiliation":"&nbsp;","affiliationURL":"#","orcidID":""}],"publishedDate":"2021-04-28T00:00:00.000+02:00","citationText":"Bolker, 2021"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>GLMM FAQ</h1>
<!--radix_placeholder_categories-->
<div class="dt-tags">
<div class="dt=tag">GLMM</div>
<div class="dt=tag">poisson</div>
<div class="dt=tag">log link</div>
<div class="dt=tag">logit</div>
<div class="dt=tag">probit</div>
</div>
<!--/radix_placeholder_categories-->
<p><p>an informal GLMM FAQ list for the r-sig-mixed-models mailing list</p></p>
</div>

<div class="d-byline">
  Ben Bolker <a href="https://github.com/Bokola" class="uri">https://github.com/Bokola</a> 
  
<br/>04-28-2021
</div>

<div class="d-article">
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">

</div>
<h1 id="introduction">Introduction</h1>
<p>This is an informal FAQ list for the <code>r-sig-mixed-models</code> mailing list.</p>
<p>The most commonly used functions for mixed modeling in R are</p>
<ul>
<li><em>linear mixed models</em>: <code>aov()</code>, <code>nlme::lme</code><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>, <code>lme4::lmer</code>; <code>brms::brm</code></li>
<li><em>generalized linear mixed models</em> (GLMMs)
<ul>
<li>frequentist: <code>MASS::glmmPQL</code>, <code>lme4::glmer</code>; <code>glmmTMB</code></li>
<li>Bayesian: <code>MCMCglmm::MCMCglmm</code>; <code>brms::brm</code></li>
</ul></li>
<li><em>nonlinear mixed models</em>: <code>nlme::nlme</code>, <code>lme4::nlmer</code>; <code>brms::brm</code></li>
<li><em>GNLMMs</em>: <code>brms::brm</code></li>
</ul>
<p>Another quick-and-dirty way to search for mixed-model related packages on CRAN:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/grep.html'>grep</a></span><span class='op'>(</span><span class='st'>"l.?m[me][^t]"</span>,<span class='fu'><a href='https://rdrr.io/r/base/colnames.html'>rownames</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/utils/available.packages.html'>available.packages</a></span><span class='op'>(</span>repos <span class='op'>=</span> <span class='st'>'https://cran.us.r-project.org'</span><span class='op'>)</span><span class='op'>)</span>,value<span class='op'>=</span><span class='cn'>TRUE</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code> [1] &quot;blmeco&quot;         &quot;buildmer&quot;       &quot;cellVolumeDist&quot;
 [4] &quot;climextRemes&quot;   &quot;elementR&quot;       &quot;glmertree&quot;     
 [7] &quot;glmmboot&quot;       &quot;glmmEP&quot;         &quot;glmmfields&quot;    
[10] &quot;glmmLasso&quot;      &quot;glmmML&quot;         &quot;glmmSeq&quot;       
[13] &quot;glmmsr&quot;         &quot;glmmTMB&quot;        &quot;lamme&quot;         
[16] &quot;lme4&quot;           &quot;lmec&quot;           &quot;lmeInfo&quot;       
[19] &quot;lmem.qtler&quot;     &quot;lmeNB&quot;          &quot;lmeNBBayes&quot;    
[22] &quot;lmeresampler&quot;   &quot;lmerTest&quot;       &quot;lmeSplines&quot;    
[25] &quot;lmeVarComp&quot;     &quot;lmmot&quot;          &quot;lmmpar&quot;        
[28] &quot;lrmest&quot;         &quot;lsmeans&quot;        &quot;mailmerge&quot;     
[31] &quot;mlmm.gwas&quot;      &quot;mlmmm&quot;          &quot;mvglmmRank&quot;    
[34] &quot;nlmeODE&quot;        &quot;nlmeU&quot;          &quot;palmerpenguins&quot;
[37] &quot;tlmec&quot;          &quot;vagalumeR&quot;     </code></pre>
</div>
<p>There are some false positives here (e.g. <code>palmerpenguins</code>); see <a href="https://xkcd.com/1313/">here</a> if you’re interested in “regex golf”.</p>
<h2 id="other-sources-of-help">Other sources of help</h2>
<ul>
<li>the mailing list is <code>r-sig-mixed-models@r-project.org</code>
<ul>
<li>sign up <a href="https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models">here</a></li>
<li>archives <a href="https://stat.ethz.ch/pipermail/r-sig-mixed-models/">here</a></li>
<li>or Google search with the tag <code>site:https://stat.ethz.ch/pipermail/r-sig-mixed-models/</code></li>
</ul></li>
<li>The source code of this document is available <a href="https://github.com/bbolker/mixedmodels-misc/blob/master/glmmFAQ.rmd">on GitHub</a>; the rendered (HTML) version lives on <a href="http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html">GitHub pages</a>.</li>
<li>Searching on StackOverflow with the <a href="http://stackoverflow.com/questions/tagged/r%20mixed-models?mode=all">[r] [mixed-models] tags</a>, or on CrossValidated with the <a href="http://stats.stackexchange.com/questions/tagged/mixed-model">[mixed-model] tag</a> may be helpful (these sites also have an <code>[lme4]</code> tag).</li>
</ul>
<p><strong>DISCLAIMERS:</strong></p>
<ul>
<li>(G)LMMs are hard - harder than you may think based on what you may have learned in your second statistics class, which probably focused on picking the appropriate sums of squares terms and degrees of freedom for the numerator and denominator of an <span class="math inline">\(F\)</span> test. ‘Modern’ mixed model approaches, although more powerful (they can handle more complex designs, lack of balance, crossed random factors, some kinds of non-Normally distributed responses, etc.), also require a new set of conceptual tools. In order to use these tools you should have at least a general acquaintance with classical mixed-model experimental designs but you should also, probably, read something about modern mixed model approaches. <span class="citation" data-cites="littell_sas_2006">@littell_sas_2006</span> and <span class="citation" data-cites="pinheiro_mixed-effects_2000">@pinheiro_mixed-effects_2000</span> are two places to start, although Pinheiro and Bates is probably more useful if you want to use R. Other useful references include <span class="citation" data-cites="gelman_data_2006">@gelman_data_2006</span> (focused on Bayesian methods) and <span class="citation" data-cites="zuur_mixed_2009">@zuur_mixed_2009</span>. If you are going to use generalized linear mixed models, you should understand generalized linear models (<span class="citation" data-cites="dobson_introduction_2008">@dobson_introduction_2008</span>, <span class="citation" data-cites="faraway_extending_2006">@faraway_extending_2006</span>, and <span class="citation" data-cites="McCullaghNelder1989">@McCullaghNelder1989</span> are standard references; the last is the canonical reference, but also the most challenging).</li>
<li>All of the issues that arise with regular linear or generalized-linear modeling (e.g.: inadequacy of p-values alone for thorough statistical analysis; need to understand how models are parameterized; need to understand the principle of marginality and how interactions can be treated; dangers of overfitting, which are not mitigated by stepwise procedures; the non-existence of free lunches) also apply, and can apply more severely, to mixed models.</li>
<li>When SAS (or Stata, or Genstat/AS-REML or …) and R differ in their answers, R may not be wrong. Both SAS and R may be `right’ but proceeding in a different way/answering different questions/using a different philosophical approach (or both may be wrong …)</li>
<li>The advice in this FAQ comes with <strong>absolutely no warranty of any sort</strong>.</li>
</ul>
<h1 id="references">References</h1>
<h2 id="linear-mixed-models">linear mixed models</h2>
<h3 id="webopen">web/open</h3>
<ul>
<li><a href="https://stats.idre.ucla.edu/other/mult-pkg/introduction-to-linear-mixed-models/">UCLA IDRE statistical consulting</a></li>
<li><span class="citation" data-cites="barr_learning_2020">@barr_learning_2020</span> Chapters 5-8</li>
</ul>
<h3 id="books-dead-treeclosed">books (dead-tree/closed)</h3>
<ul>
<li>pinheiro_mixed-effects_2000: LMM only.</li>
<li><span class="citation" data-cites="zuur_mixed_2009">@zuur_mixed_2009</span>: Focused on ecology.</li>
<li><span class="citation" data-cites="gelman_data_2006">@gelman_data_2006</span>: LMM and GLMM; Bayesian; examples from social science. Intermediate mathematics.</li>
<li>(Rethinking)</li>
</ul>
<h1 id="model-definition">Model definition</h1>
<h2 id="model-specification">Model specification</h2>
<p>The following formula extensions for specifying random-effects structures in R are used by</p>
<ul>
<li><code>lme4</code></li>
<li><code>nlme</code> (nested effects only, although crossed effects can be specified with more work)</li>
<li><code>glmmADMB</code> and <code>glmmTMB</code></li>
</ul>
<p><code>MCMCglmm</code> uses a different specification, inherited from AS-REML.</p>
<p>(Modified from Robin Jeffries, UCLA:)</p>
<div class="layout-chunk" data-layout="l-body">
<table style="width:92%;">
<colgroup>
<col style="width: 45%" />
<col style="width: 45%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">formula</th>
<th style="text-align: left;">meaning</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><code>(1|group)</code></td>
<td style="text-align: left;">random group intercept</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>(x|group)</code> = <code>(1+x|group)</code></td>
<td style="text-align: left;">random slope of x within group with correlated intercept</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>(0+x|group)</code> = <code>(-1+x|group)</code></td>
<td style="text-align: left;">random slope of x within group: no variation in intercept</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>(1|group) + (0+x|group)</code></td>
<td style="text-align: left;">uncorrelated random intercept and random slope within group</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>(1|site/block)</code> = <code>(1|site)+(1|site:block)</code></td>
<td style="text-align: left;">intercept varying among sites and among blocks within sites (nested random effects)</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>site+(1|site:block)</code></td>
<td style="text-align: left;"><em>fixed</em> effect of sites plus random variation in intercept among blocks within sites</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>(x|site/block)</code> = <code>(x|site)+(x|site:block)</code> = <code>(1 + x|site)+(1+x|site:block)</code></td>
<td style="text-align: left;">slope and intercept varying among sites and among blocks within sites</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>(x1|site)+(x2|block)</code></td>
<td style="text-align: left;">two different effects, varying at different levels</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>x*site+(x|site:block)</code></td>
<td style="text-align: left;">fixed effect variation of slope and intercept varying among sites and random variation of slope and intercept among blocks within sites</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>(1|group1)+(1|group2)</code></td>
<td style="text-align: left;">intercept varying among crossed random effects (e.g. site, year)</td>
</tr>
</tbody>
</table>
</div>
<p>Or in a little more detail:</p>
<div class="layout-chunk" data-layout="l-body">
<table style="width:92%;">
<colgroup>
<col style="width: 45%" />
<col style="width: 45%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">equation</th>
<th style="text-align: left;">formula</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(ÃŸ_0 + ÃŸ_{1}X_{i} + e_{si}\)</span></td>
<td style="text-align: left;">n/a (Not a mixed-effects model)</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\((ÃŸ_0 + b_{S,0s}) + ÃŸ_{1}X_i + e_{si}\)</span></td>
<td style="text-align: left;"><code>~ X + (1|Subject)</code></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\((ÃŸ_0 + b_{S,0s}) + (ÃŸ_{1} + b_{S,1s}) X_i + e_{si}\)</span></td>
<td style="text-align: left;"><code>~ X + (1 + X|Subject)</code></td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\((ÃŸ_0 + b_{S,0s} + b_{I,0i}) + (ÃŸ_{1} + b_{S,1s}) X_i + e_{si}\)</span></td>
<td style="text-align: left;"><code>~ X + (1 + X|Subject) + (1|Item)</code></td>
</tr>
<tr class="odd">
<td style="text-align: left;">As above, but <span class="math inline">\(S_{0s}\)</span>, <span class="math inline">\(S_{1s}\)</span> independent</td>
<td style="text-align: left;"><code>~ X + (1|Subject) + (0 + X| Subject) + (1|Item)</code></td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\((ÃŸ_0 + b_{S,0s} + b_{I,0i}) + ÃŸ_{1}X_i + e_{si}\)</span></td>
<td style="text-align: left;"><code>~ X + (1|Subject) + (1|Item)</code></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\((ÃŸ_0 + b_{I,0i}) + (ÃŸ_{1} + b_{S,1s})X_i + e_{si}\)</span></td>
<td style="text-align: left;"><code>~ X + (0 + X|Subject) + (1|Item)</code></td>
</tr>
</tbody>
</table>
</div>
<p>Modified from: <a href="http://stats.stackexchange.com/questions/13166/rs-lmer-cheat-sheet?lq=1" class="uri">http://stats.stackexchange.com/questions/13166/rs-lmer-cheat-sheet?lq=1</a> (Livius)</p>
<p>The <strong>magic</strong> development version of the <a href="https://github.com/datalorax/equatiomatic">equatiomatic package</a> can handle mixed models (<code>remotes::install_github("datalorax/equatiomatic")</code>), e.g.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://github.com/lme4/lme4/'>lme4</a></span><span class='op'>)</span>
<span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://github.com/datalorax/equatiomatic'>equatiomatic</a></span><span class='op'>)</span>
<span class='va'>fm1</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/lme4/man/lmer.html'>lmer</a></span><span class='op'>(</span><span class='va'>Reaction</span> <span class='op'>~</span> <span class='va'>Days</span> <span class='op'>+</span> <span class='op'>(</span><span class='va'>Days</span><span class='op'>|</span><span class='va'>Subject</span><span class='op'>)</span>, <span class='va'>sleepstudy</span><span class='op'>)</span>
<span class='fu'>equatiomatic</span><span class='fu'>::</span><span class='fu'><a href='https://rdrr.io/pkg/equatiomatic/man/extract_eq.html'>extract_eq</a></span><span class='op'>(</span><span class='va'>fm1</span><span class='op'>)</span>
</code></pre>
</div>
<p><span class="math display">\[
\begin{aligned}
  \operatorname{Reaction}_{i}  &amp;\sim N \left(\alpha_{j[i]} + \beta_{1j[i]}(\operatorname{Days}), \sigma^2 \right) \\    
\left(
  \begin{array}{c} 
    \begin{aligned}
      &amp;\alpha_{j} \\
      &amp;\beta_{1j}
    \end{aligned}
  \end{array}
\right)
  &amp;\sim N \left(
\left(
  \begin{array}{c} 
    \begin{aligned}
      &amp;\mu_{\alpha_{j}} \\
      &amp;\mu_{\beta_{1j}}
    \end{aligned}
  \end{array}
\right)
, 
\left(
  \begin{array}{cc}
     \sigma^2_{\alpha_{j}} &amp; \rho_{\alpha_{j}\beta_{1j}} \\ 
     \rho_{\beta_{1j}\alpha_{j}} &amp; \sigma^2_{\beta_{1j}}
  \end{array}
\right)
 \right)
    \text{, for Subject j = 1,} \dots \text{,J}
\end{aligned}
\]</span></p>
</div>
<p>It doesn’t handle GLMMs (yet), but you could fit two fake models — one LMM like your GLMM but with a Gaussian response, and one GLM with the same family/link function as your GLMM but without the random effects — and put the pieces together.</p>
<p>More possibly useful links:</p>
<ul>
<li>Rense Nieuwenhuis’s <a href="http://www.rensenieuwenhuis.nl/r-sessions-16-multilevel-model-specification-lme4/">blogpost/lesson on lme4 model specification</a></li>
<li>CrossValidated’s <a href="https://stats.stackexchange.com/questions/13166/rs-lmer-cheat-sheet">lmer cheat sheet</a></li>
<li>Kristoffer Magnusson’s <a href="https://rpsychologist.com/r-guide-longitudinal-lme-lmer">Using R and lme/lmer to fit different two- and three-level longitudinal models</a></li>
</ul>
<h2 id="should-i-treat-factor-xxx-as-fixed-or-random">Should I treat factor xxx as fixed or random?</h2>
<p>This is in general a far more difficult question than it seems on the surface. There are many competing philosophies and definitions. For example, from <span class="citation" data-cites="gelman_analysis_2005">@gelman_analysis_2005</span>:</p>
<blockquote>
<p>Before discussing the technical issues, we briefly review what is meant by fixed and random effects. It turns out that different—in fact, incompatible—definitions are used in different contexts. [See also Kreft and de Leeuw (1998), Section 1.3.3, for a discussion of the multiplicity of definitions of fixed and random effects and coefficients, and Robinson (1998) for a historical overview.] Here we outline five definitions that we have seen: 1. Fixed effects are constant across individuals, and random effects vary. For example, in a growth study, a model with random intercepts αi and fixed slope β corresponds to parallel lines for different individuals i, or the model yit = αi + βt. Kreft and de Leeuw [(1998), page 12] thus distinguish between fixed and random coefficients. 2. Effects are fixed if they are interesting in themselves or random if there is interest in the underlying population. Searle, Casella and McCulloch [(1992), Section 1.4] explore this distinction in depth. 3. “When a sample exhausts the population, the corresponding variable is fixed; when the sample is a small (i.e., negligible) part of the population the corresponding variable is random” [Green and Tukey (1960)]. 4. “If an effect is assumed to be a realized value of a random variable, it is called a random effect” [LaMotte (1983)]. 5. Fixed effects are estimated using least squares (or, more generally, maximum likelihood) and random effects are estimated with shrinkage [“linear unbiased prediction” in the terminology of Robinson (1991)]. This definition is standard in the multilevel modeling literature [see, e.g., Snijders and Bosker (1999), Section 4.2] and in econometrics.</p>
</blockquote>
<p>Another useful comment (via Kevin Wright) reinforcing the idea that “random vs. fixed” is not a simple, cut-and-dried decision: from <span class="citation" data-cites="schabenberger_contemporary_2001">@schabenberger_contemporary_2001</span>, p. 627:</p>
<blockquote>
<p>Before proceeding further with random field linear models we need to remind the reader of the adage that one modeler’s random effect is another modeler’s fixed effect.</p>
</blockquote>
<p><span class="citation" data-cites="clark2015should">@clark2015should</span> address this question from a mostly econometric perspective, focusing mostly on practical variance/bias/RMSE criteria.</p>
<p>One point of particular relevance to ‘modern’ mixed model estimation (rather than ‘classical’ method-of-moments estimation) is that, for practical purposes, there must be a reasonable number of random-effects levels (e.g. blocks) – more than 5 or 6 at a minimum. This is not surprising if you consider that random effects estimation is trying to estimate an among-block variance. For example, from <span class="citation" data-cites="Crawley2002">@Crawley2002</span> p. 670:</p>
<blockquote>
<p>Are there enough levels of the factor in the data on which to base an estimate of the variance of the population of effects? No, means [you should probably treat the variable as] fixed effects.</p>
</blockquote>
<p>Some researchers (who treat fixed vs random as a philosophical rather than a pragmatic decision) object to this approach.</p>
<p>Also see a very thoughtful chapter in <span class="citation" data-cites="hodges_richly_2016">@hodges_richly_2016</span>.</p>
<p>Treating factors with small numbers of levels as random will in the best case lead to very small and/or imprecise estimates of random effects; in the worst case it will lead to various numerical difficulties such as lack of convergence, zero variance estimates, etc.. (A small <a href="https:/rpubs.com/bbolker/4187">simulation exercise</a> shows that at least the estimates of the standard deviation are downwardly biased in this case; it’s not clear whether/how this bias would affect the point estimates of fixed effects or their estimated confidence intervals.) In the classical method-of-moments approach these problems may not arise (because the sums of squares are always well defined as long as there are at least two units), but the underlying problems of lack of power are there nevertheless.</p>
<p>Also see <a href="https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q2/003709.html">this thread</a> on the r-sig-mixed-models mailing list.</p>
<h2 id="nested-or-crossed">Nested or crossed?</h2>
<p><a id="nested_or_crossed"></a></p>
<ul>
<li>Relatively few mixed effect modeling packages can handle crossed random effects, i.e. those where one level of a random effect can appear in conjunction with more than one level of another effect. (This definition is confusing, and I would happily accept a better one.) A classic example is crossed temporal and spatial effects. If there is random variation among temporal blocks (e.g. years) ‘’and’’ random variation among spatial blocks (e.g. sites), ‘’and’’ if there is a consistent year effect across sites and ‘’vice versa’’, then the random effects should be treated as crossed.</li>
<li><code>lme4</code> does handled crossed effects, efficiently; if you need to deal with crossed REs in conjunction with some of the features that <code>nlme</code> offers (e.g. heteroscedasticity of residuals via <code>weights</code>/<code>varStruct</code>, correlation of residuals via <code>correlation</code>/<code>corStruct</code>, see p. 163ff of <span class="citation" data-cites="pinheiro_mixed-effects_2000">@pinheiro_mixed-effects_2000</span> (section 4.2.2: <a href="http://tinyurl.com/crossedRE">Google books link</a>)</li>
<li>I rarely find it useful to think of fixed effects as “nested” (although others disagree); if for example treatments A and B are only measured in block 1, and treatments C and D are only measured in block 2, one still assumes (because they are fixed effects) that each treatment would have the same effect if applied in the other block. (One might like to estimate treatment-by-block interactions, but in this case the experimental design doesn’t allow it; one would have to have multiple treatments measured within each block, although not necessarily all treatments in every block.) One would code this analysis as <code>response~treatment+(1|block)</code> in <code>lme4</code>. Also, in the case of fixed effects, crossed and nested specifications change the parameterization of the model, but not anything else (e.g. the number of parameters estimated, log-likelihood, model predictions are all identical). That is, in R’s <code>model.matrix</code> function (which implements a version of Wilkinson-Rogers notation) <code>a*b</code> and <code>a/b</code> (which expand to <code>1+a+b+a:b</code> and <code>1+a+a:b</code> respectively) give model matrices with the same number of columns.</li>
<li>Whether you explicitly specify a random effect as nested or not depends (in part) on the way the levels of the random effects are coded. If the ‘lower-level’ random effect is coded with unique levels, then the two syntaxes <code>(1|a/b)</code> (or <code>(1|a)+(1|a:b)</code>) and <code>(1|a)+(1|b)</code> are equivalent. If the lower-level random effect has the same labels within each larger group (e.g. blocks 1, 2, 3, 4 within sites A, B, and C) then the explicit nesting <code>(1|a/b)</code> is required. It seems to be considered best practice to code the nested level uniquely (e.g. A1, A2, …, B1, B2, …) so that confusion between nested and crossed effects is less likely.</li>
</ul>
<h2 id="when-can-i-include-a-predictor-as-both-fixed-and-random">(When) can I include a predictor as both fixed and random?</h2>
<p>See <a href="https://www.muscardinus.be/2017/08/fixed-and-random/">blog post by Thierry Onkelinx</a></p>
<h1 id="model-extensions">Model extensions</h1>
<h2 id="overdispersion">Overdispersion</h2>
<p><a id="overdispersion"></a></p>
<h3 id="testing-for-overdispersioncomputing-overdispersion-factor">Testing for overdispersion/computing overdispersion factor</h3>
<ul>
<li>with the usual caveats, plus a few extras – counting degrees of freedom, etc. – the usual procedure of calculating the sum of squared Pearson residuals and comparing it to the residual degrees of freedom should give at least a crude idea of overdispersion. The following attempt counts each variance or covariance parameter as one model degree of freedom and presents the sum of squared Pearson residuals, the ratio of (SSQ residuals/rdf), the residual df, and the <span class="math inline">\(p\)</span>-value based on the (approximately!!) appropriate <span class="math inline">\(\chi^2\)</span> distribution. <strong>Do PLEASE note the usual, and extra, caveats noted here: this is an APPROXIMATE estimate of an overdispersion parameter</strong>. Even in the GLM case, the expected deviance per point equaling 1 is only true as the distribution of individual deviates approaches normality, i.e. the usual <span class="math inline">\(\lambda&gt;5\)</span> rules of thumb for Poisson values and <span class="math inline">\(\textrm{min}(Np, N(1-p)) &gt; 5\)</span> for binomial values (e.g. see <span class="citation" data-cites="venables_modern_2002">@venables_modern_2002</span>, <a href="http://books.google.com/books?id=974c4vKurNkC&amp;pg=PA209">p. 208-209</a>). (And that’s without the extra complexities due to GLMM, i.e. the “effective” residual df should be large enough to make the sums of squares converge on a <span class="math inline">\(\chi^2\)</span> distribution …)</li>
<li>Remember that (1) overdispersion is irrelevant for models that estimate a scale parameter (i.e. almost anything but Poisson or binomial: Gaussian, Gamma, negative binomial …) and (2) overdispersion is not estimable (and hence practically irrelevant) for Bernoulli models (= binary data = binomial with <span class="math inline">\(N=1\)</span>).</li>
<li>The recipes below may need adjustment for some of the more complex model types allowed by <code>glmmTMB</code> (e.g. zero-inflation/variable dispersion), where it’s less clear what to measure to estimate overdispersion.</li>
</ul>
<p>The following function should work for a variety of model types (at least <code>glmmADMB</code>, <code>glmmTMB</code>, <code>lme4</code>, …).</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>overdisp_fun</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>model</span><span class='op'>)</span> <span class='op'>{</span>
    <span class='va'>rdf</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/df.residual.html'>df.residual</a></span><span class='op'>(</span><span class='va'>model</span><span class='op'>)</span>
    <span class='va'>rp</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/residuals.html'>residuals</a></span><span class='op'>(</span><span class='va'>model</span>,type<span class='op'>=</span><span class='st'>"pearson"</span><span class='op'>)</span>
    <span class='va'>Pearson.chisq</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/sum.html'>sum</a></span><span class='op'>(</span><span class='va'>rp</span><span class='op'>^</span><span class='fl'>2</span><span class='op'>)</span>
    <span class='va'>prat</span> <span class='op'>&lt;-</span> <span class='va'>Pearson.chisq</span><span class='op'>/</span><span class='va'>rdf</span>
    <span class='va'>pval</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/Chisquare.html'>pchisq</a></span><span class='op'>(</span><span class='va'>Pearson.chisq</span>, df<span class='op'>=</span><span class='va'>rdf</span>, lower.tail<span class='op'>=</span><span class='cn'>FALSE</span><span class='op'>)</span>
    <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span>chisq<span class='op'>=</span><span class='va'>Pearson.chisq</span>,ratio<span class='op'>=</span><span class='va'>prat</span>,rdf<span class='op'>=</span><span class='va'>rdf</span>,p<span class='op'>=</span><span class='va'>pval</span><span class='op'>)</span>
<span class='op'>}</span>
</code></pre>
</div>
</div>
Example:
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://github.com/lme4/lme4/'>lme4</a></span><span class='op'>)</span>
<span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://github.com/glmmTMB/glmmTMB'>glmmTMB</a></span><span class='op'>)</span>
</code></pre>
</div>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>101</span><span class='op'>)</span>  
<span class='va'>d</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/data.frame.html'>data.frame</a></span><span class='op'>(</span>x<span class='op'>=</span><span class='fu'><a href='https://rdrr.io/r/stats/Uniform.html'>runif</a></span><span class='op'>(</span><span class='fl'>1000</span><span class='op'>)</span>,
                f<span class='op'>=</span><span class='fu'><a href='https://rdrr.io/r/base/factor.html'>factor</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/sample.html'>sample</a></span><span class='op'>(</span><span class='fl'>1</span><span class='op'>:</span><span class='fl'>10</span>,size<span class='op'>=</span><span class='fl'>1000</span>,replace<span class='op'>=</span><span class='cn'>TRUE</span><span class='op'>)</span><span class='op'>)</span><span class='op'>)</span>
<span class='fu'><a href='https://rdrr.io/r/base/message.html'>suppressMessages</a></span><span class='op'>(</span><span class='va'>d</span><span class='op'>$</span><span class='va'>y</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/simulate.html'>simulate</a></span><span class='op'>(</span><span class='op'>~</span><span class='va'>x</span><span class='op'>+</span><span class='op'>(</span><span class='fl'>1</span><span class='op'>|</span><span class='va'>f</span><span class='op'>)</span>, family<span class='op'>=</span><span class='va'>poisson</span>,
                          newdata<span class='op'>=</span><span class='va'>d</span>,
                          newparams<span class='op'>=</span><span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span>theta<span class='op'>=</span><span class='fl'>1</span>,beta<span class='op'>=</span><span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>0</span>,<span class='fl'>2</span><span class='op'>)</span><span class='op'>)</span><span class='op'>)</span><span class='op'>[[</span><span class='fl'>1</span><span class='op'>]</span><span class='op'>]</span><span class='op'>)</span>
<span class='va'>m1</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/lme4/man/glmer.html'>glmer</a></span><span class='op'>(</span><span class='va'>y</span><span class='op'>~</span><span class='va'>x</span><span class='op'>+</span><span class='op'>(</span><span class='fl'>1</span><span class='op'>|</span><span class='va'>f</span><span class='op'>)</span>,data<span class='op'>=</span><span class='va'>d</span>,family<span class='op'>=</span><span class='va'>poisson</span><span class='op'>)</span>
<span class='fu'>overdisp_fun</span><span class='op'>(</span><span class='va'>m1</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>       chisq        ratio          rdf            p 
1035.9966325    1.0391140  997.0000000    0.1902294 </code></pre>
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>m2</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/glmmTMB/man/glmmTMB.html'>glmmTMB</a></span><span class='op'>(</span><span class='va'>y</span><span class='op'>~</span><span class='va'>x</span><span class='op'>+</span><span class='op'>(</span><span class='fl'>1</span><span class='op'>|</span><span class='va'>f</span><span class='op'>)</span>,data<span class='op'>=</span><span class='va'>d</span>,family<span class='op'>=</span><span class='st'>"poisson"</span><span class='op'>)</span>
<span class='fu'>overdisp_fun</span><span class='op'>(</span><span class='va'>m2</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>       chisq        ratio          rdf            p 
1035.9961394    1.0391135  997.0000000    0.1902323 </code></pre>
</div>
<p>The <code>gof</code> function in the <code>aods3</code> provides similar functionality (it reports both deviance- and <span class="math inline">\(\chi^2\)</span>-based estimates of overdispersion and tests).</p>
<h3 id="fitting-models-with-overdispersion">Fitting models with overdispersion?</h3>
<ul>
<li><p>quasilikelihood estimation: <a href="http://finzi.psych.upenn.edu/R/library/MASS/html/glmmPQL.html">MASS::glmmPQL</a>. Quasi- was deemed unreliable in <code>lme4</code>, and is no longer available. (Part of the problem was questionable numerical results in some cases; the other problem was that DB felt that he did not have a sufficiently good understanding of the theoretical framework that would explain what the algorithm was actually estimating in this case.) <a href="http://finzi.psych.upenn.edu/R/library/geepack/html/geeglm.html">geepack::geelgm</a> may be workable (haven’t tried it)</p>
<p>If you really want quasi-likelihood analysis for <code>glmer</code> fits, you can do it yourself by adjusting the coefficient table - i.e., by multiplying the standard error by the square root of the dispersion factor <a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> and recomputing the <span class="math inline">\(Z\)</span>- and <span class="math inline">\(p\)</span>-values accordingly, as follows:</p></li>
</ul>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'>## extract summary table; you may also be able to do this via</span>
<span class='co'>##  broom::tidy or broom.mixed::tidy</span>
<span class='va'>quasi_table</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>model</span>,<span class='va'>ctab</span><span class='op'>=</span><span class='fu'><a href='https://rdrr.io/r/stats/coef.html'>coef</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/summary.html'>summary</a></span><span class='op'>(</span><span class='va'>model</span><span class='op'>)</span><span class='op'>)</span>,
                           <span class='va'>phi</span><span class='op'>=</span><span class='fu'>overdisp_fun</span><span class='op'>(</span><span class='va'>model</span><span class='op'>)</span><span class='op'>[</span><span class='st'>"ratio"</span><span class='op'>]</span><span class='op'>)</span> <span class='op'>{</span>
    <span class='va'>qctab</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/with.html'>within</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/as.data.frame.html'>as.data.frame</a></span><span class='op'>(</span><span class='va'>ctab</span><span class='op'>)</span>,
    <span class='op'>{</span>   <span class='va'>`Std. Error`</span> <span class='op'>&lt;-</span> <span class='va'>`Std. Error`</span><span class='op'>*</span><span class='fu'><a href='https://rdrr.io/r/base/MathFun.html'>sqrt</a></span><span class='op'>(</span><span class='va'>phi</span><span class='op'>)</span>
        <span class='va'>`z value`</span> <span class='op'>&lt;-</span> <span class='va'>Estimate</span><span class='op'>/</span><span class='va'>`Std. Error`</span>
        <span class='va'>`Pr(&gt;|z|)`</span> <span class='op'>&lt;-</span> <span class='fl'>2</span><span class='op'>*</span><span class='fu'><a href='https://rdrr.io/r/stats/Normal.html'>pnorm</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/MathFun.html'>abs</a></span><span class='op'>(</span><span class='va'>`z value`</span><span class='op'>)</span>, lower.tail<span class='op'>=</span><span class='cn'>FALSE</span><span class='op'>)</span>
    <span class='op'>}</span><span class='op'>)</span>
    <span class='kw'><a href='https://rdrr.io/r/base/function.html'>return</a></span><span class='op'>(</span><span class='va'>qctab</span><span class='op'>)</span>
<span class='op'>}</span>
<span class='fu'><a href='https://rdrr.io/r/stats/printCoefmat.html'>printCoefmat</a></span><span class='op'>(</span><span class='fu'>quasi_table</span><span class='op'>(</span><span class='va'>m1</span><span class='op'>)</span>,digits<span class='op'>=</span><span class='fl'>3</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)   0.2277     0.2700    0.84      0.4    
x             2.0640     0.0528   39.11   &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'>## to use this with glmmTMB, we need to separate out the</span>
<span class='co'>##  conditional component of the summary</span>
<span class='fu'><a href='https://rdrr.io/r/stats/printCoefmat.html'>printCoefmat</a></span><span class='op'>(</span><span class='fu'>quasi_table</span><span class='op'>(</span><span class='va'>m2</span>,
                         ctab<span class='op'>=</span><span class='fu'><a href='https://rdrr.io/r/stats/coef.html'>coef</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/summary.html'>summary</a></span><span class='op'>(</span><span class='va'>m2</span><span class='op'>)</span><span class='op'>)</span><span class='op'>[[</span><span class='st'>"cond"</span><span class='op'>]</span><span class='op'>]</span><span class='op'>)</span>,
             digits<span class='op'>=</span><span class='fl'>3</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)   0.2277     0.2700    0.84      0.4    
x             2.0640     0.0528   39.09   &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
<p>Another version, this one tidyverse-centric:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='http://github.com/bbolker/broom.mixed'>broom.mixed</a></span><span class='op'>)</span>
<span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://dplyr.tidyverse.org'>dplyr</a></span><span class='op'>)</span>
<span class='va'>tidy_quasi</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>model</span>, <span class='va'>phi</span><span class='op'>=</span><span class='fu'>overdisp_fun</span><span class='op'>(</span><span class='va'>model</span><span class='op'>)</span><span class='op'>[</span><span class='st'>"ratio"</span><span class='op'>]</span>,
                       <span class='va'>conf.level</span><span class='op'>=</span><span class='fl'>0.95</span><span class='op'>)</span> <span class='op'>{</span>
    <span class='va'>tt</span> <span class='op'>&lt;-</span> <span class='op'>(</span><span class='fu'><a href='https://generics.r-lib.org/reference/tidy.html'>tidy</a></span><span class='op'>(</span><span class='va'>model</span>, effects<span class='op'>=</span><span class='st'>"fixed"</span><span class='op'>)</span>
        <span class='op'>%&gt;%</span> <span class='fu'><a href='https://dplyr.tidyverse.org/reference/mutate.html'>mutate</a></span><span class='op'>(</span>std.error<span class='op'>=</span><span class='va'>std.error</span><span class='op'>*</span><span class='fu'><a href='https://rdrr.io/r/base/MathFun.html'>sqrt</a></span><span class='op'>(</span><span class='va'>phi</span><span class='op'>)</span>,
                   statistic<span class='op'>=</span><span class='va'>estimate</span><span class='op'>/</span><span class='va'>std.error</span>,
                   p.value<span class='op'>=</span><span class='fl'>2</span><span class='op'>*</span><span class='fu'><a href='https://rdrr.io/r/stats/Normal.html'>pnorm</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/MathFun.html'>abs</a></span><span class='op'>(</span><span class='va'>statistic</span><span class='op'>)</span>, lower.tail<span class='op'>=</span><span class='cn'>FALSE</span><span class='op'>)</span><span class='op'>)</span>
    <span class='op'>)</span>
    <span class='kw'><a href='https://rdrr.io/r/base/function.html'>return</a></span><span class='op'>(</span><span class='va'>tt</span><span class='op'>)</span>
<span class='op'>}</span>
<span class='fu'>tidy_quasi</span><span class='op'>(</span><span class='va'>m1</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code># A tibble: 2 x 6
  effect term        estimate std.error statistic p.value
  &lt;chr&gt;  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
1 fixed  (Intercept)    0.228    0.270      0.843   0.399
2 fixed  x              2.06     0.0528    39.1     0    </code></pre>
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'>tidy_quasi</span><span class='op'>(</span><span class='va'>m2</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code># A tibble: 2 x 7
  effect component term        estimate std.error statistic p.value
  &lt;chr&gt;  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
1 fixed  cond      (Intercept)    0.228    0.270      0.843   0.399
2 fixed  cond      x              2.06     0.0528    39.1     0    </code></pre>
</div>
<p>These functions make some simplifying assumptions: (1) this overdispersion computation is approximate</p>
<p>In this case using quasi-likelihood doesn’t make much difference, since the data we simulated in the first place were Poisson.) Keep in mind that once you switch to quasi-likelihood you will either have to eschew inferential methods such as the likelihood ratio test, profile confidence intervals, AIC, etc., or make more heroic assumptions to compute “quasi-” analogs of all of the above (such as QAIC).</p>
<ul>
<li>observation-level random effects (OLRE: this approach should work in most packages). If you want to a citation for this approach, try <span class="citation" data-cites="elston_analysis_2001">@elston_analysis_2001</span>, who cite <span class="citation" data-cites="lawson_disease_1999">@lawson_disease_1999</span>; apparently there is also an example in section 10.5 of <span class="citation" data-cites="maindonald_data_2010">@maindonald_data_2010</span>, and (according to an R-sig-mixed-models post) this is also discussed by <span class="citation" data-cites="rabehesketh_multilevel_2008">@rabehesketh_multilevel_2008</span>. Also see <span class="citation" data-cites="browne_variance_2005">@browne_variance_2005</span> for an example in the binomial context (i.e. logit-normal-binomial rather than lognormal-Poisson). Agresti’s excellent (2002) book <span class="citation" data-cites="agresti_categorical_2002">@agresti_categorical_2002</span> also discusses this (section 13.5), referring back to <span class="citation" data-cites="breslow_extrapoisson_1984">@breslow_extrapoisson_1984</span> and <span class="citation" data-cites="hinde_compound_1982">@hinde_compound_1982</span>. [<strong>Notes</strong>: (a) I haven’t checked all these references myself, (b) I can’t find the reference any more, but I have seen it stated that observation-level random effect estimation is probably dodgy for PQL approaches as used in Elston et al 2001]</li>
<li>alternative distributions
<ul>
<li>Poisson-lognormal model for counts or binomial-logit-Normal model for proportions (see above, “observation-level random effects”)</li>
<li>negative binomial for counts or beta-binomial for proportions
<ul>
<li><code>lme4::glmer.nb()</code> should fit a negative binomial, although it is somewhat slow and fragile compared to some of the other methods suggested here. <code>lme4</code> cannot fit beta-binomial models (these cannot be formulated as a part of the exponential family of distributions)</li>
<li><a href="https://github.com/glmmtmb/glmmTMB/">glmmTMB</a> will fit two parameterizations of the negative binomial: <code>family="nbinom2"</code> gives the classic parameterization with <span class="math inline">\(\sigma^2=\mu(1+\mu/k)\)</span> (“NB2” in Hardin and Hilbe’s terminology) while <code>family="nbinom1"</code> gives a parameterization with <span class="math inline">\(\sigma^2=\phi \mu\)</span>, <span class="math inline">\(\phi&gt;1\)</span> (“NB1” to Hardin and Hilbe). The latter might also be called a “quasi-Poisson” parameterization because it matches the mean-variance relationship assumed by quasi-Poisson models, i.e. the variance is strictly proportional to the mean (although the proportionality constant must be &gt;1, a limitation that does not apply to quasi-likelihood approaches). (<a href="http://github.com/bbolker/glmmADMB/">glmmADMB</a> will also fit these models, with <code>family="nbinom"</code> for NB2, but is deprecated in favour of glmmTMB.)</li>
<li><code>glmmTMB</code> allows beta-binomial models (<span class="citation" data-cites="harrison_comparison_2015">[@harrison_comparison_2015]</span> suggests comparing beta-binomial with OLRE models to assess reliability)</li>
<li>the <code>brms</code> package has a <code>negbinomial</code> family (no beta-binomial, but it does have a wide range of other families)</li>
</ul></li>
</ul></li>
<li>other packages/approaches (less widely used, or requiring a bit more effort)
<ul>
<li><code>gamlss.mx:gamlssNP</code></li>
<li>WinBUGS/JAGS (via R2WinBUGS/Rjags)</li>
<li>AD Model Builder (possibly via <code>R2admb</code> package) or <code>TMB</code></li>
<li><code>gnlmm</code> in the <code>repeated</code> package (<a href="http://www.commanster.eu/rcode.html">off-CRAN</a>)</li>
<li><a href="http://www.asreml.com/software/genstat/htmlhelp/server/GLMM.htm">ASREML</a></li>
</ul></li>
</ul>
<p>Negative binomial models in <code>glmmTMB</code> and lognormal-Poisson models in <code>glmer</code> (or <code>MCMCglmm</code>) are probably the best quick alternatives for overdispersed count data. If you need to explore alternatives (different variance-mean relationships, different distributions), then <code>ADMB</code>, <code>TMB</code>, <code>WinBUGS</code>, <code>Stan</code>, <code>NIMBLE</code> are the most flexible alternatives.</p>
<h3 id="underdispersion">Underdispersion</h3>
<p>Underdispersion (much <em>less</em> variability than expected) is a less common problem than overdispersion.</p>
<ul>
<li>mild overdispersion is sometimes ignored, since it tends in general to lead to conservative rather than anti-conservative results</li>
<li>quasi-likelihood (and the quasi-hack listed above) can handle under- as well as underdispersion</li>
<li>some other solutions exist, but are less widely implemented
<ul>
<li>for distributions with a small range (e.g. litter sizes of large mammals), one can treat responses as ordinal (e.g. using the <code>ordinal</code> package, or <code>MCMCglmm</code> or <code>brms</code> for Bayesian solutions)</li>
<li>the COM-Poisson distribution and generalized Poisson distributions, implemented in <code>glmmTMB</code>, can handle underdispersion (J. Hilbe recommends the latter in <a href="https://stats.stackexchange.com/questions/67385/what-is-the-appropriate-model-for-underdispersed-count-data">this CrossValidated answer</a>). (<code>VGAM</code> has a generalized Poisson distribution, but doesn’t handle random effects.)</li>
</ul></li>
</ul>
<h2 id="gamma-glmms">Gamma GLMMs</h2>
<p>While one (well, OK I) would naively think that GLMMs with Gamma distributions would be just as easy (or hard) as any other sort of GLMMs, it seems that they are in fact harder to implement. Basic simulated examples of Gamma GLMMs can fail in lme4 despite analogous problems with Poisson, binomial, etc. distributions. Solutions: - the default inverse link seems particularly problematic; try other links (especially <code>family=Gamma(link="log")</code>) if that is possible/makes sense - consider whether a lognormal model (i.e. a regular LMM on logged data) would work/makes sense. - <span class="citation" data-cites="lo_transform_2015">@lo_transform_2015</span> argue that the Gamma family with an <em>identity</em> link is superior to lognormal models for reaction-time data. I (BMB) don’t find their argument particularly convincing, but lots of people want to do this. Unfortunately this is technically challenging (see <a href="https://github.com/lme4/lme4/issues/573">here</a>), because it is likely that some “illegal” values (predicted responses <span class="math inline">\(\le 0\)</span>) will occur while fitting the model, even if the final fitted model makes no impossible predictions. Thus something has to be done to make the model-fitting machinery tolerant of such values (i.e. returning <code>NA</code> for these model evaluations, or clamping illegal values to the constrained space with an appropriate smooth penalty function).</p>
<p>Gamma models can be fitted by a wide variety of platforms (<code>lme4::glmer</code>, <code>MASS::glmmPQL</code>, <code>glmmADMB</code>, <code>glmmTMB</code>, <code>MixedModels.jl</code>, <code>MCMCglmm</code>, <code>brms</code> … not sure about others.</p>
<h2 id="beta-glmms">Beta GLMMs</h2>
<p>Proportion data where the denominator (e.g. maximum possible number of successes for a given observation) is not known can be modeled using a Beta distribution. <span class="citation" data-cites="smithson_better_2006">@smithson_better_2006</span> is a good introduction for non-statisticians (<em>not</em> in the mixed-model case), and the <code>betareg</code> package <span class="citation" data-cites="cribari-neto_beta_2009">[@cribari-neto_beta_2009]</span> handles <em>non</em>-mixed Beta regressions. The <code>glmmTMB</code> and <code>brms</code> packages handle Beta mixed models (<code>brms</code> also handles zero-inflated and zero-one inflated models).</p>
<h2 id="zero-inflation">Zero-inflation</h2>
<p>See e.g. <span class="citation" data-cites="martin_zero_2005">@martin_zero_2005</span> or <span class="citation" data-cites="warton_many_2005">@warton_many_2005</span> (“many zeros does not mean zero inflation”) or <span class="citation" data-cites="zuur_zero-truncated_2009">@zuur_zero-truncated_2009</span> for general information on zero-inflation.</p>
<h3 id="count-data">Count data</h3>
<ul>
<li><code>MCMCglmm</code> handles zero-truncated, zero-inflated, and zero-altered models, although specifying the models is a little bit tricky: see Sections 5.3 to 5.5 of the <a href="https://cran.r-project.org/web/packages/MCMCglmm/vignettes/CourseNotes.pdf">CourseNotes vignette</a></li>
<li><code>glmmADMB</code> handles
<ul>
<li>zero-inflated models (with a single zero-inflation parameter – i.e., the level of zero-inflation is assumed constant across the whole data set)</li>
<li>truncated Poisson and negative binomial distributions (which allows two-stage fitting of hurdle models)</li>
</ul></li>
<li><code>glmmTMB</code> handles a variety of Z-I and Z-T models (allows covariates, and random effects, in the zero-alteration model)</li>
<li><code>brms</code> does too</li>
<li>so does <code>GLMMadaptive</code></li>
<li>Gavin Simpson has a <a href="http://www.fromthebottomoftheheap.net/2017/05/04/compare-mgcv-with-glmmTMB/">detailed writeup</a> showing that <code>mgcv::gam()</code> can do simple mixed models (Poisson, not NB) with zero-inflation, and comparing <code>mgcv</code> with <code>glmmTMB</code> results</li>
<li><code>gamlssNP</code> in the <code>gamlss.mx</code> package should handle zero-inflation, and the <code>gamlss.tr</code> package should handle truncated (i.e. hurdle) models – but I haven’t tried them</li>
<li>roll-your-own: ADMB/R2admb, WinBUGS/R2WinBUGS, TMB, Stan, …</li>
</ul>
<h3 id="continuous-data">Continuous data</h3>
<p>Continuous data are a special case where the mixture model for zero-inflated data is less relevant, because observations that are exactly zero occur with <em>probability</em> (but not probability density) zero. There are two cases of interest:</p>
<h4 id="probability-density-of-x-zero-or-infinite">Probability density of <span class="math inline">\(x\)</span> zero or infinite</h4>
<p>In this case zero is a problematic observation for the distribution; it’s either impossible or infinitely (locally) likely. Some examples:</p>
<ul>
<li>Gamma distribution: probability density at zero is infinite (if shape&lt;1) or zero (if shape&gt;1); it’s finite only for an exponential distribution (shape==1)</li>
<li>Lognormal distribution: the probability density at zero is zero.</li>
<li>Beta distribution: the probability densities at 0 and 1 are zero (if the corresponding shape parameter is &gt;1) or infinite (if shape&lt;1)</li>
</ul>
<p>The best solution depends very much on the data-generating mechanism.</p>
<ul>
<li>If the bad (0/1) values are generated by rounding (e.g. proportions that are too close to the boundaries are reported as being on the boundaries), the simplest solution is to “squeeze” these in slightly, e.g. <span class="math inline">\(y \to (y +a)/2a\)</span> for some sensible value of <span class="math inline">\(a\)</span> <span class="citation" data-cites="smithson_better_2006">[@smithson_better_2006]</span></li>
<li>If you think that zero values are generated by a separate process, the simplest solution is to fit a Bernoulli model to the zero/non-zero data, then a <em>conditional</em> continuous model for the non-zero values; this is effectively a <em>hurdle model</em>.</li>
<li>you might have <em>censored</em> data where all values below a certain limit (e.g. a detection limit) are recorded as zero; in this case you might be able to use <code>survreg()</code> and <code>frailty()</code> in the <code>survival</code> package for random-intercept models (as <a href="https://stat.ethz.ch/pipermail/r-help/2003-June/034905.html">suggested on r-help by Thomas Lumley in 2003</a> or <a href="https://stackoverflow.com/questions/25317021/interaction-terms-and-random-effects-in-tobit-regression-model-in-r">on StackOverflow by user 42- in 2014</a>. The <a href="https://CRAN.R-project.org/package=lmec">lmec package</a> handles <em>linear</em> mixed models.</li>
<li>The <code>cplm</code> package handles ‘Tweedie compound Poisson linear models’, which in a particular range of parameters allows for skewed continuous responses with a spike at zero</li>
</ul>
<h4 id="probability-density-of-x-positive-and-finite">Probability density of <span class="math inline">\(x\)</span> positive and finite</h4>
<p>In this case (e.g. a spike of zeros in the center of an otherwise continuous distribution), the hurdle model probably makes the most sense.</p>
<h3 id="tests-for-zero-inflation">Tests for zero-inflation</h3>
<ul>
<li>you can use a likelihood ratio test between the regular and zero-inflated version of the model, but be aware of boundary issues (search “boundary” elsewhere on this page …) – the null value (no zero inflation) is on the boundary of the feasible space</li>
<li>you can use AIC or variations, with the same caveats</li>
<li>you can use Vuong’s test, which is often recommended for testing zero-inflation in GLMs, because under some circumstances the various model flavors under consideration (hurdle vs zero-inflated vs “vanilla”) are not nested. Vuong’s test is implemented (and referenced) in the <code>pscl</code> package, and should be feasible to implement for GLMMs, but I don’t know of an implementation. Someone should let me (BMB) know if they find one.</li>
<li>two untested but reasonable approaches:
<ul>
<li>use a <code>simulate()</code> method if it exists to construct a simulated distribution of the proportion of zeros expected overall from your model, and compare it to the observed proportion of zeros in the data set</li>
<li>compute the probability of a zero for each observation. On the basis of (conditionally) independent Bernoulli trials, compute the expected number of zeros and the confidence intervals – compare it with the observed number.</li>
</ul></li>
</ul>
<h2 id="spatial-and-temporal-correlation-models-heteroscedasticity-r-side-models">Spatial and temporal correlation models, heteroscedasticity (“R-side” models)</h2>
<p>In <code>nlme</code> these so-called <strong>R-side</strong> (R for “residual”) structures are accessible via the <code>weights</code>/<code>VarStruct</code> (heteroscedasticity) and <code>correlation</code>/<code>corStruct</code> (spatial or temporal correlation) arguments and data structures. This extension is a bit harder than it might seem. In LMMs it is a natural extension to allow the residual error terms to be components of a single multivariate normal draw; if that MVN distribution is uncorrelated and homoscedastic (i.e. proportional to an identity matrix) we get the classic model, but we can in principle allow it to be correlated and/or heteroscedastic.</p>
<p>It is not too hard to define marginal correlation structures that don’t make sense. One class of reasonably sensible models is to always assume an observation-level random effect (as MCMCglmm does for computational reasons) and to allow that random effect to be MVN on the link scale (so that the full model is lognormal-Poisson, logit-normal binomial, etc., depending on the link function and family).</p>
<p>For example, a relatively simple Poisson model with spatially correlated errors might look like this:</p>
<p><span class="math display">\[
\begin{split}
\eta &amp; \sim \textrm{MVN}(a + b x, \Sigma) \\
\Sigma_{ij} &amp; = \sigma^2 \exp(-d_{ij}/s) \\
y_i &amp; \sim \textrm{Poisson}(\lambda=\exp(\eta_i))
\end{split}
\]</span></p>
<p>That is, the marginal distributions of the response values are Poisson-lognormal, but on the link (log) scale the latent Normal variables underlying the response are <em>multivariate</em> normal, with a variance-covariance matrix described by an exponential spatial correlation function with scale parameter <span class="math inline">\(s\)</span>.</p>
<p>How can one achieve this?</p>
<ul>
<li>These types of models are not implemented in <code>lme4</code>, for either LMMs or GLMMs; they are fairly low priority, and it is hard to see how they could be implemented for GLMMs (the equivalent for LMMs is tedious but should be straightforward to implement).</li>
<li>For LMMs, you can use the spatial/temporal correlation structures that are built into (n)lme</li>
<li>You can use the spatial/temporal correlation structures available for (n)lme, which include basic geostatistical (space) and ARMA-type (time) models.
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'>sos</span><span class='op'>)</span>
<span class='fu'><a href='https://rdrr.io/pkg/sos/man/findFn.html'>findFn</a></span><span class='op'>(</span><span class='st'>"corStruct"</span><span class='op'>)</span>
</code></pre>
</div></li>
</ul>
</div>
<p>finds additional possibilities in the <code>ramps</code> (extended geostatistical) and <code>ape</code> (phylogenetic) packages.</p>
<ul>
<li>You can use these structures in GLMMs via <code>MASS::glmmPQL</code> (see Dormann et al.)</li>
<li>geepack::geeglm</li>
<li>geoR, geoRglm (power tools); these are mostly designed for fitting spatial random field GLMMs via MCMC – not sure that they do random effects other than the spatial random effect</li>
<li><a href="http://r-inla.org">R-INLA</a> (super-power tool)</li>
<li>it is possible to use AD Model Builder to fit spatial GLMMs, as shown in these <a href="http://admb-project.org/examples/spatial-models">AD Model Builder examples</a>; this capability is not in the <code>glmmADMB</code> package (and may not be for a while!), but it would be possible to run AD Model Builder via the R2admb package (requires installing – and learning! ADMB)</li>
<li><a href="http://mathstat.helsinki.fi/openbugs/Manuals/GeoBUGS/Manual.html">geoBUGS</a>, the geostatistical/spatial correlation module for WinBUGS, is another alternative (but again requires going outside of R)</li>
</ul>
<h2 id="penalizationhandling-complete-separation">Penalization/handling complete separation</h2>
<p><em>Complete separation</em> occurs in a binary-response model when there is some linear combination of the parameters that perfectly separates failures from successes - for example, when all of the observations are zero for some particular combination of categories. The symptoms of this problem are unrealistically large parameter estimates; ridiculously large Wald standard errors (the <em>Hauck-Donner effect</em>); and various warnings.</p>
<p>In particular, binomial <code>glmer()</code> models with complete separation can lead to “Downdated VtV is not positive definite” (e.g. see <a href="https://github.com/lme4/lme4/issues/483">here</a>) or “PIRLS step-halvings failed to reduce deviance in pwrssUpdate” errors (e.g. see <a href="https://github.com/lme4/lme4/issues/179#issuecomment-424445187">here</a>). Roughly speaking, the complete separation is likely to appear even if one considers only the fixed effects part of the model (counterarguments or counterexamples welcome!), suggesting two quick-and-dirty diagnostic methods. If <code>fixed_form</code> is the formula including only the fixed effects:</p>
<ul>
<li><code>summary(g1 &lt;- glm(fixed_form, family=binomial, data=...))</code> will show one or more of the following symptoms:
<ul>
<li>warnings that <code>glm.fit: fitted probabilities numerically 0 or 1 occurred</code></li>
<li>parameter estimates of large magnitude (e.g. <code>any(abs(g1)&gt;8)</code>, assuming that predictors are either categorical or scaled to have standard deviations of <span class="math inline">\(\approx 1\)</span>)</li>
<li>extremely large Wald standard errors, and large p-values (<em>Hauck-Donner effect</em>)</li>
<li>the <code>brglm2</code> package has a method for detecting complete separation: <code>library("brglm2"); glm(fixed_form, data = ..., family = binomial, method="detect_separation")</code>. This should say whether complete separation occurs, and in which (combinations of) variables, e.g.</li>
</ul></li>
</ul>
<pre><code>Separation: TRUE 
Existence of maximum likelihood estimates
(Intercept)      height 
        Inf         Inf 
0: finite value, Inf: infinity, -Inf: -infinity</code></pre>
<p>If complete separation is occurring between categories of a single categorical fixed-effect predictor with a large number of levels, one option would be to treat this fixed effect as a random effect, which will allow some degree of shrinkage to the mean. (It might be reasonable to specify the variance of this term <em>a priori</em> to a large value [minimal shrinkage], rather than trying to estimate it from the data.)</p>
<p>(<strong>TODO</strong>: worked example)</p>
<p>The general approach to handling complete separation in logistic regression is called <em>penalized regression</em>; it’s available in the <code>brglm</code>, <code>brglm2</code>, <code>logistf</code>, and <code>rms</code> packages. However, these packages don’t handle mixed models, so the best available <em>general</em> approach is to use a Bayesian method that allows you to set a prior on the fixed effects, e.g. a Gaussian with standard deviation of 3; this can be done in any of the Bayesian GLMM packages (e.g. <code>blme</code>, <code>MCMCglmm</code>, <code>brms</code>, …) (See <a href="http://bbolker.github.io/mixedmodels-misc/ecostats_chap.html#digression-complete-separation">supplementary material for Fox et al. 2016</a> for a worked example.)</p>
<h2 id="non-gaussian-random-effects">Non-Gaussian random effects</h2>
<p>I’m not aware of easy ways to fit mixed models with non-Gaussian random effects distributions in R (i.e., convenient, flexible, well-tested implementations). <span class="citation" data-cites="mcculloch_misspecifying_2011">@mcculloch_misspecifying_2011</span> discusses when this misspecification may be important. <a href="https://niasra.uow.edu.au/content/groups/public/@web/@inf/@math/documents/mm/uow236296.pdf">This presentation</a> discusses various approaches to solving the problem (e.g. using a Gamma rather than a Normal distribution of REs in log-link models). The <code>spaMM</code> package implements H-likelihood models <span class="citation" data-cites="lee_generalized_2017">[@lee_generalized_2017]</span>, and claims to allow a range of random-effects distributions (perhaps not well tested though …)</p>
<p>In principle you can implement any random-effects distribution you want in a fully capable Bayesian modeling language (e.g. JAGS/Stan/PyMC/etc.); see e.g. <a href="https://stackoverflow.com/questions/45656714/user-defined-random-intercept-distribution-for-glmer">this StackOverflow answer</a>, which uses the <code>rethinking</code> package’s interface to Stan.</p>
<h1 id="estimation">Estimation</h1>
<h2 id="what-methods-are-available-to-fit-estimate-glmms">What methods are available to fit (estimate) GLMMs?</h2>
<p>(adapted from Bolker et al TREE 2009)</p>
<div class="layout-chunk" data-layout="l-body">
<table>
<colgroup>
<col style="width: 23%" />
<col style="width: 24%" />
<col style="width: 26%" />
<col style="width: 26%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Method</th>
<th style="text-align: left;">Advantages</th>
<th style="text-align: left;">Disadvantages</th>
<th style="text-align: left;">Packages</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Penalized quasi-likelihood</td>
<td style="text-align: left;">Flexible, widely implemented</td>
<td style="text-align: left;">Likelihood inference may be inappropriate; biased for large variance or small means</td>
<td style="text-align: left;">PROC GLIMMIX (SAS), GLMM (GenStat), glmmPQL (R:MASS), ASREML-R</td>
</tr>
<tr class="even">
<td style="text-align: left;">Laplace approximation</td>
<td style="text-align: left;">More accurate than PQL</td>
<td style="text-align: left;">Slower and less flexible than PQL</td>
<td style="text-align: left;">glmer (R:lme4,lme4a), glmm.admb (R:glmmADMB), INLA, glmmTMB, AD Model Builder, HLM</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Gauss-Hermite quadrature</td>
<td style="text-align: left;">More accurate than Laplace</td>
<td style="text-align: left;">Slower than Laplace; limited to 2-3 random effects</td>
<td style="text-align: left;">PROC NLMIXED (SAS), glmer (R:lme4, lme4a), glmmML (R:glmmML), xtlogit (Stata)</td>
</tr>
<tr class="even">
<td style="text-align: left;">Markov chain Monte Carlo</td>
<td style="text-align: left;">Highly flexible, arbitrary number of random effects; accurate</td>
<td style="text-align: left;">Slow, technically challenging, Bayesian framework</td>
<td style="text-align: left;">MCMCglmm (R:MCMCglmm), rstanarm (R), brms (R), MCMCpack (R), WinBUGS/OpenBUGS (R interface: BRugs/R2WinBUGS), JAGS (R interface: rjags/R2jags), AD Model Builder (R interface: R2admb), glmm.admb (post hoc MCMC after Laplace fit) (R:glmmADMB)</td>
</tr>
</tbody>
</table>
</div>
<h2 id="troubleshooting">Troubleshooting</h2>
<ul>
<li>double-check the model specification and the data for mistakes</li>
<li>center and scale continuous predictor variables (e.g. with <code>scale()</code>)</li>
<li>try all available optimizers (e.g. several different implementations of BOBYQA and Nelder-Mead, L-BFGS-B from <code>optim</code>, <code>nlminb()</code>, …). While this will of course be slow for large fits, we consider it the gold standard; if all optimizers converge to values that are practically equivalent (it’s up to the user to decide what “practically equivalent means for their case”), then we would consider the model fit to be good enough. For example:
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>modelfit.all</span> <span class='op'>&lt;-</span> <span class='fu'>lme4</span><span class='fu'>::</span><span class='fu'><a href='https://rdrr.io/pkg/lme4/man/allFit.html'>allFit</a></span><span class='op'>(</span><span class='va'>model</span><span class='op'>)</span>
<span class='va'>ss</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/summary.html'>summary</a></span><span class='op'>(</span><span class='va'>modelfit.all</span><span class='op'>)</span>
</code></pre>
</div></li>
</ul>
</div>
<h3 id="convergence-warnings">Convergence warnings</h3>
<p>Most of the current advice about troubleshooting <code>lme4</code> convergence problems can be found in the help page <code>?convergence</code>. That page explains that the convergence tests in the current version of <code>lme4</code> (1.1-11, February 2016) generate lots of false positives. We are considering raising the gradient warning threshold to 0.01 in future releases of <code>lme4</code>. In addition to the general troubleshooting tips above:</p>
<ul>
<li>double-check the Hessian calculation with the more expensive Richardson extrapolation method (see examples)</li>
<li>restart the fit from the apparent optimum, or from a point perturbed slightly away from the optimum (<code>getME(model,c("theta","beta"))</code> should retrieve the parameters in a form suitable to be used as the <code>start</code> parameter)</li>
<li>a common error is to specify an offset to a log-link model as a raw searching-effort value, i.e. <code>offset(effort)</code> rather than <code>offset(log(effort))</code>. While the intention is to fit a model where <span class="math inline">\(\textrm{counts} \propto \textrm{effort}\)</span>, specifying <code>offset(effort)</code> leads to a model where <span class="math inline">\(\textrm{counts} \propto \exp(\textrm{effort})\)</span> instead; <code>exp(effort)</code> is often a huge (and model-destabilizing) number.</li>
</ul>
<p><a id="singular-fit"></a> <a id="zero-variance"></a></p>
<h3 id="singular-models-random-effect-variances-estimated-as-zero-or-correlations-estimated-as---1">Singular models: random effect variances estimated as zero, or correlations estimated as +/- 1</h3>
<p>It is very common for overfitted mixed models to result in singular fits. Technically, singularity means that some of the <span class="math inline">\(\boldsymbol \theta\)</span> (variance-covariance Cholesky decomposition) parameters corresponding to diagonal elements of the Cholesky factor are exactly zero, which is the edge of the feasible space, or equivalently that the variance-covariance matrix has some zero eigenvalues (i.e. is positive semidefinite rather than positive definite), or (<em>almost</em> equivalently) that some of the variances are estimated as zero or some of the correlations are estimated as +/-1. This commonly occurs in two scenarios:</p>
<ul>
<li><p>small numbers of random-effect levels (e.g. &lt;5), as illustrated in <a href="http://rpubs.com/bbolker/4187">these simulations</a> and discussed (in a somewhat different, Bayesian context) by <span class="citation" data-cites="gelman_prior_2006">@gelman_prior_2006</span>.</p></li>
<li><p>complex random-effects models, e.g. models of the form <code>(f|g)</code> where <code>f</code> is a categorical variable with a relatively large number of levels, or models with several different random-slopes terms.</p></li>
<li><p>When using <code>lme4</code>, singularity is most obviously detectable in the output of <code>summary.merMod()</code> or <code>VarCorr.merMod()</code> when a variance is estimated as 0 (or very small, i.e. orders of magnitude smaller than other variance components) or when a correlation is estimated as exactly <span class="math inline">\(\pm 1\)</span>. However, as pointed out by <span class="citation" data-cites="bates_parsimonious_2015">@bates_parsimonious_2015</span>, singularities in larger variance-covariance matrices can be hard to detect: checking for small values among the diagonal elements of the Cholesky factor is a good start.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>theta</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/lme4/man/getME.html'>getME</a></span><span class='op'>(</span><span class='va'>model</span>,<span class='st'>"theta"</span><span class='op'>)</span>
<span class='co'>## diagonal elements are identifiable because they are fitted</span>
<span class='co'>##  with a lower bound of zero ...</span>
<span class='va'>diag.element</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/lme4/man/getME.html'>getME</a></span><span class='op'>(</span><span class='va'>model</span>,<span class='st'>"lower"</span><span class='op'>)</span><span class='op'>==</span><span class='fl'>0</span>
<span class='fu'><a href='https://rdrr.io/r/base/any.html'>any</a></span><span class='op'>(</span><span class='va'>theta</span><span class='op'>[</span><span class='va'>diag.element</span><span class='op'>]</span><span class='op'>&lt;</span><span class='fl'>1e-5</span><span class='op'>)</span>
</code></pre>
</div></li>
</ul>
</div>
<p>As of <code>lme4</code> version 1.1-19, this functionality is available as <code>isSingular(model)</code>. - In <code>MCMCglmm</code>, singular or near-singular models will provoke an error and a requirement to specify a stronger prior.</p>
<p>At present there are a variety of strong opinions about how to resolve such problems. Briefly:</p>
<ul>
<li><span class="citation" data-cites="barr_random_2013">@barr_random_2013</span> suggest always starting with the maximal model (i.e. the most random-effects component of the model that is <em>theoretically</em> identifiable given the experimental design) and then dropping terms when singularity or non-convergence occurs (please see the paper for detailed recommendations …)</li>
<li><span class="citation" data-cites="matuschek_balancing_2017">@matuschek_balancing_2017</span> and <span class="citation" data-cites="bates_parsimonious_2015">@bates_parsimonious_2015</span> strongly disagree, suggesting that models should be simplified <em>a priori</em> whenever possible; they also provide <a href="https://github.com/dmbates/RePsychLing">tools</a> for diagnosing and mitigating singularity.</li>
<li>One alternative (suggested by Robert LaBudde) for the small-numbers-of-levels scenario is to “fit the model with the random factor as a fixed effect, get the level coefficients in the sum to zero form, and then compute the standard deviation of the coefficients.” This is appropriate for users who are (a) primarily interested in measuring variation (i.e. the random effects are not just nuisance parameters, and the variability [rather than the estimated values for each level] is of scientific interest), (b) unable or unwilling to use other approaches (e.g. MCMC with half-Cauchy priors in WinBUGS), (c) unable or unwilling to collect more data. For the simplest case (balanced, orthogonal, nested designs with normal errors) these estimates of standard deviations should equal the classical method-of-moments estimates.</li>
<li>Bayesian approaches allow the user to specify a informative prior that avoids singularity.
<ul>
<li>The <code>blme</code> package <span class="citation" data-cites="chung_nondegenerate_2013">[@chung_nondegenerate_2013]</span> provides a wrapper for the <code>lme4</code> machinery that adds a particular form of weak prior to get an approximate a Bayesian maximum <em>a posteriori</em> estimate that avoids singularity.</li>
<li>The <code>MCMCglmm</code> package allows for priors on the variance-covariance matrix</li>
<li>The <code>rstanarm</code> and <code>brms</code> packages provide wrappers for the Stan Hamiltonian MCMC engine that fit GLMMs via <code>lme4</code> syntax, again allowing a variety of priors to be set.</li>
</ul></li>
<li>If a variance component is zero, dropping it from the model will have no effect on any of the estimated quantities (although it will affect the AIC, as the variance parameter is counted even though it has no effect). <span class="citation" data-cites="pasch_interspecific_2013">@pasch_interspecific_2013</span> gives one example where random effects were dropped because the variance components were consistently estimated as zero. Conversely, if one chooses for philosophical grounds to retain these parameters, it won’t change any of the answers.</li>
</ul>
<h3 id="setting-residual-variances-to-a-fixed-value-zero-or-other">Setting residual variances to a fixed value (zero or other)</h3>
<p>For some problems it would be convenient to be able to set the residual variance term to zero, or a fixed value. This is difficult in <code>lme4</code>, because the model is parameterized internally in such a way that the residual variance is profiled out (i.e., calculated directly from a residual deviance term) and the random-effects variances are scaled by the residual variance.</p>
<p><a href="https://www.google.ca/search?q=site%3A%2F%2Fstat.ethz.ch%2Fpipermail%2Fr-sig-mixed-models%2F+fix+residual+variance">Searching the r-sig-mixed-models list for “fix residual variance”</a></p>
<ul>
<li>This is done in the <code>metafor</code> package, for meta-analytic models</li>
<li>You can use the <code>blme</code> package to fix the residual variance: from Vincent Dorie,</li>
</ul>
<pre><code>library(blme)
blmer(formula = y ~ 1 + (1 | group), weights = V,
      resid.prior = point(1.0), cov.prior = NULL)</code></pre>
This sets the residual variance to 1.0. You <em>cannot</em> use this to make it exactly zero, but you can make it very small (and experiment with setting it to different small values, e.g. 0.001 vs 0.0001, to see how sensitive the results are). - Similarly, you can fix the residual variance to a small positive value in <code>[n]lme</code> via the <code>control()</code> argument <span class="citation" data-cites="heisterkamp_update_2017">[@heisterkamp_update_2017]</span>:
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'>nlme</span><span class='fu'>::</span><span class='fu'><a href='https://rdrr.io/pkg/nlme/man/lme.html'>lme</a></span><span class='op'>(</span><span class='va'>Reaction</span><span class='op'>~</span><span class='va'>Days</span>,random<span class='op'>=</span><span class='op'>~</span><span class='fl'>1</span><span class='op'>|</span><span class='va'>Subject</span>,
          data<span class='op'>=</span><span class='fu'>lme4</span><span class='fu'>::</span><span class='va'><a href='https://rdrr.io/pkg/lme4/man/sleepstudy.html'>sleepstudy</a></span>,
          control<span class='op'>=</span><span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span>sigma<span class='op'>=</span><span class='fl'>1e-8</span><span class='op'>)</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<ul>
<li>the <code>glmmTMB</code> package can set the residual variance to zero, by specifying <code>dispformula = ~0</code></li>
<li>There is an <a href="https://CRAN.R-project.org/package=rrBlupMethod6">rrBlupMethod6 package</a> on CRAN (“Re-parametrization of mixed model formulation to allow for a fixed residual variance when using RR-BLUP for genom[e]wide estimation of marker effects”), but it seems fairly special-purpose.</li>
<li>it might be possible <em>in principle</em> to adapt <code>lme4</code>’s internal <code>devfun2()</code> function (used in the likelihood profiling computation for LMMs), which uses a specified value of the residual standard deviation in computing likelihood, but as <span class="citation" data-cites="bates_fitting_2015">@bates_fitting_2015</span> say:</li>
</ul>
<blockquote>
<p>The resulting function is not useful for general nonlinear optimization — one can easily wander into parameter regimes corresponding to infeasible (non-positive semidefinite) variance-covariance matrices — but it serves for likelihood profiling, where one focal parameter is varied at a time and the optimization over the other parameters is likely to start close to an optimum.</p>
</blockquote>
<h3 id="other-problemslme4-error-messages">Other problems/<code>lme4</code> error messages</h3>
<p>Most of the following error messages are relatively unusual, and happen mostly with complex/large/unstable models. There is often no simple fix; the standard suggestions for troubleshooting are (1) try rescaling and/or centering predictors; (2) see if a simpler model can be made to work; (3) look for severe lack of balance and/or complete separation in the data set.</p>
<ul>
<li><code>PIRLS step-halvings failed to reduce deviance in pwrssUpdate</code>
<ul>
<li>this can also occur due to complete or quasi-complete separation (see <a href="#penalizationhandling-complete-separation">Penalization/handling complete separation</a></li>
<li>When using <code>lme4</code> to fit GLMMs with link functions that do not automatically constrain the response to the allowable range of the distributional family (e.g. binomial models with a log link, where the estimated probability can be &gt;1, or inverse-Gamma models, where the estimated mean can be negative), it is not unusual to get this error. This occurs because <code>lme4</code> doesn’t do anything to constrain the predicted values, so <code>NaN</code> values pop up, which aren’t handled gracefully. If possible, switch to a link function to one that constrains the response (e.g. logit link for binomial or log link for Gamma).</li>
<li>otherwise this message often occurs when there is something else wrong with the model or data, e.g.  - <a href="https://stackoverflow.com/questions/28036334/using-glmer-nb-the-error-messagemaxstephalfit-pirls-step-halvings-failed-t">a model fitted to underdispersed data includes both a negative binomial response and observation-level random effects</a> - <a href="https://stackoverflow.com/questions/37533825/error-maxstephalfit-pirls-step-halvings-failed-to-reduce-deviance-in-pwrssupd">negative response values for a link function that doesn’t allow them</a></li>
</ul></li>
<li><code>Downdated VtV is not positive definite</code>: no specific advice, see general suggestions above</li>
<li><code>convergence code 3 from bobyqa: bobyqa -- a trust region step failed to reduce q</code>: again no specific advice about fixing this, although there is a <a href="https://stats.stackexchange.com/questions/89945/meaning-of-a-convergence-warning-in-glmer">useful discussion of the meaning of the error message on CrossValidated</a></li>
</ul>
<h2 id="reml-for-glmms">REML for GLMMs</h2>
<ul>
<li>While restricted maximum likelihood (REML) procedures (<a href="http://en.wikipedia.org/wiki/Restricted_maximum_likelihood">Wikipedia</a> are well established for linear mixed models, it is less clear how one should define and compute the equivalent criteria (integrating out the effects of fixed parameters) for GLMMs. <span class="citation" data-cites="millar_maximum_2011">@millar_maximum_2011</span> and <span class="citation" data-cites="berger_integrated_1999">@berger_integrated_1999</span> are possible starting points in the peer-reviewed literature, and there are mailing-list discussions of these issues <a href="https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q1/002104.html">here</a> and <a href="http://lists.admb-project.org/pipermail/users/2011-June/001224.html">here</a>.</li>
<li>Attempting to use <code>REML=TRUE</code> with <code>glmer</code> will produce the warning <code>extra argument(s) ‘REML’ disregarded</code></li>
<li><code>glmmTMB</code> allows <code>REML=TRUE</code> for GLMMs (it uses the Laplace approximation to integrate over the fixed effect parameters), since version 0.2.2</li>
</ul>
<h1 id="model-diagnostics">Model diagnostics</h1>
<h1 id="inference-and-confidence-intervals">Inference and confidence intervals</h1>
<h2 id="testing-hypotheses">Testing hypotheses</h2>
<h3 id="what-are-the-p-values-listed-by-summaryglmerfit-etc.-are-they-reliable">What are the p-values listed by <code>summary(glmerfit)</code> etc.? Are they reliable?</h3>
<p>By default, in keeping with the tradition in analysis of generalized linear models, <code>lme4</code> and similar packages display the Wald Z-statistics for each parameter in the model summary. These have one big advantage: they’re convenient to compute. However, they are asymptotic approximations, assuming both that (1) the sampling distributions of the parameters are multivariate normal (or equivalently that the log-likelihood surface is quadratic) and that (2) the sampling distribution of the log-likelihood is (proportional to) <span class="math inline">\(\chi^2\)</span>. The second approximation is discussed further under “Degrees of freedom”. The first assumption usually requires an even greater leap of faith, and is known to cause problems in some contexts (for binomial models failures of this assumption are called the <em>Hauck-Donner effect</em>), especially with extreme-valued parameters.</p>
<h3 id="methods-for-testing-single-parameters">Methods for testing single parameters</h3>
<p>From worst to best:</p>
<ul>
<li>Wald <span class="math inline">\(Z\)</span>-tests</li>
<li><strong>For balanced, nested LMMs</strong> where degrees of freedom can be computed according to classical rules: Wald <span class="math inline">\(t\)</span>-tests</li>
<li>Likelihood ratio test, either by setting up the model so that the parameter can be isolated/dropped (via <code>anova</code> or <code>drop1</code>, or via computing likelihood profiles</li>
<li>Markov chain Monte Carlo (MCMC) or parametric bootstrap confidence intervals</li>
</ul>
<h3 id="tests-of-effects-i.e.-testing-that-several-parameters-are-simultaneously-zero">Tests of effects (i.e. testing that several parameters are simultaneously zero)</h3>
<p>From worst to best:</p>
<ul>
<li>Wald chi-square tests (e.g. <code>car::Anova</code>)</li>
<li>Likelihood ratio test (via <code>anova</code> or <code>drop1</code>)</li>
<li><strong>For balanced, nested LMMs</strong> where df can be computed: conditional F-tests</li>
<li><strong>For LMMs</strong>: conditional F-tests with df correction (e.g. Kenward-Roger in <code>pbkrtest</code> package: see notes on K-R etc <a href="#ddf">below</a>.</li>
<li>MCMC or parametric, or nonparametric, bootstrap comparisons (nonparametric bootstrapping must be implemented carefully to account for grouping factors)</li>
</ul>
<h3 id="is-the-likelihood-ratio-test-reliable-for-mixed-models">Is the likelihood ratio test reliable for mixed models?</h3>
<ul>
<li>It depends.</li>
<li>Not for fixed effects in finite-size cases (see <span class="citation" data-cites="pinheiro_mixed-effects_2000">@pinheiro_mixed-effects_2000</span>): may depend on ‘denominator degrees of freedom’ (number of groups) and/or total number of samples - total number of parameters</li>
<li>Conditional F-tests are preferred for LMMs, <strong>if</strong> denominator degrees of freedom are known</li>
</ul>
<p><a id="ddf"></a></p>
<h3 id="why-doesnt-lme4-display-denominator-degrees-of-freedomp-values-what-other-options-do-i-have">Why doesn’t <code>lme4</code> display denominator degrees of freedom/p values? What other options do I have?</h3>
<p>There is an <a href="http://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-are-p_002dvalues-not-displayed-when-using-lmer_0028_0029_003f">R FAQ entry</a> on this topic, which links to a <a href="https://stat.ethz.ch/pipermail/r-help/2006-May/094765.html">mailing list post</a> by Doug Bates (there is also a voluminous <a href="http://rwiki.sciviews.org/doku.php?id=guides:lmer-tests">mailing list thread</a> reproduced on the R wiki). The bottom line is</p>
<ul>
<li>For special cases that correspond to classical experimental designs (i.e. balanced designs that are nested, split-plot, randomized block, etc.) … we can show that the null distributions of particular ratios of sums of squares follow an <span class="math inline">\(F\)</span> distribution with known numerator and denominator degrees of freedom (and hence the sampling distributions of particular contrasts are t-distributed with known df). In more complicated situations (unbalanced, GLMMs, crossed random effects, models with temporal or spatial correlation, etc.) it is not in general clear that the null distribution of the computed ratio of sums of squares is really an F distribution, for <em>any</em> choice of denominator degrees of freedom.</li>
<li>For each simple degrees-of-freedom recipe that has been suggested (trace of the hat matrix, etc.) there seems to be at least one fairly simple counterexample where the recipe fails badly (e.g. see <a href="https://stat.ethz.ch/pipermail/r-help/2006-September/112495.html">this r-help thread from September 2006</a>).</li>
<li>When the responses are normally distributed and the design is balanced, nested etc. (i.e. the classical LMM situation), the scaled deviances and differences in deviances are exactly <span class="math inline">\(F\)</span>-distributed and looking at the experimental design (i.e., which treatments vary/are replicated at which levels) tells us what the relevant degrees of freedom are (see “df alternatives” below)</li>
<li>Two approaches to approximating df (Satterthwaite and Kenward-Roger) have been implemented in R, Satterthwaite in <code>lmerTest</code> and Kenward-Roger in <code>pbkrtest</code> (as <code>KRmodcomp</code>) (various packages such as <code>lmerTest</code>, <code>emmeans</code>, <code>car</code>, etc., import <code>pbkrtest::get_Lb_ddf</code>).
<ul>
<li><p>K-R is probably the most reliable option <span class="citation" data-cites="schaalje_adequacy_2002">[@schaalje_adequacy_2002]</span>, although it may be prohibitively computationally expensive for large data sets.</p></li>
<li><p>K-R was derived for LMMs (and for REML?) in particular, it isn’t clear how it would apply to GLMMs. <span class="citation" data-cites="stroup_rethinking_2014">@stroup_rethinking_2014</span> states (referencing <span class="citation" data-cites="stroup_non-normal_2013">@stroup_non-normal_2013</span>) that K-R actually works reasonably well for GLMMs (K-R is not implemented in R for GLMMs; Stroup suggests that a pseudo-likelihood <span class="citation" data-cites="wolfinger_generalized_1993">[@wolfinger_generalized_1993]</span> approach is necessary in order to implement K-R for GLMMs):</p>
<blockquote>
<p>Notice the non-integer values of the denominator df. They, and the <span class="math inline">\(F\)</span> and <span class="math inline">\(p\)</span> values, reflect the procedure developed by Kenward and Roger (2009) to account for the effect of the covariance structure on degrees of freedom and standard errors. Although the Kenward–Roger adjustment was derived for the LMM with normally distributed data and is an ad hoc procedure for GLMMs with non-normal data, informal simulation studies consistently have suggested that the adjustment is accurate. The Kenward-Roger adjustment requires that the SAS GLIMMIX default computing algorithm, pseudo-likelihood, be used rather than the Laplace algorithm used to obtain AICC statistics. Stroup (2013b) found that for binomial and Poisson GLMMs, pseudo-likelihood with the Kenward–Roger adjustment yields better Type I error control than Laplace while preserving the GLMM’s advantage with respect to power and accuracy in estimating treatment means.</p>
</blockquote></li>
</ul></li>
<li>There are several different issues at play in finite-size (small-sample) adjustments, which apply slightly differently to LMMs and GLMMs.
<ul>
<li>When the data don’t fit into the classical framework (crossed, unbalanced, R-side effects), we might still guess that the deviances etc. are approximately F-distributed but that we don’t know the real degrees of freedom – this is what the Satterthwaite, Kenward-Roger, Fai-Cornelius, etc. approximations are supposed to do.</li>
<li>When the responses are not normally distributed (as in GLMs and GLMMs), and when the scale parameter is not estimated (as in standard Poisson- and binomial-response models), then the deviance differences are only asymptotically F- or chi-square-distributed (i.e. not for our real, finite-size samples). In standard GLM practice, we usually ignore this problem; there is some literature on finite-size corrections for GLMs under the rubrics of “Bartlett corrections” and “higher order asymptotics” (see <span class="citation" data-cites="McCullaghNelder1989">@McCullaghNelder1989</span>, <span class="citation" data-cites="cordeiro_improved_1994">@cordeiro_improved_1994</span>, <span class="citation" data-cites="cordeiro_note_1998">@cordeiro_note_1998</span> and the <code>cond</code> package (<a href="https://cran.r-project.org/package=cond">on CRAN</a>) [which works with GLMs, not GLMMs]), but it’s rarely used. (The bias correction/Firth approach implemented in the <code>brglm</code> package attempts to address the problem of finite-size bias, not finite-size non-chi-squaredness of the deviance differences.)</li>
<li>When the scale parameter in a GLM is estimated rather than fixed (as in Gamma or quasi-likelihood models), it is sometimes recommended to use an <span class="math inline">\(F\)</span> test to account for the uncertainty of the scale parameter (e.g. <span class="citation" data-cites="venables_modern_2002">@venables_modern_2002</span> recommend <code>anova(...,test="F")</code> for quasi-likelihood models)</li>
<li>Combining these issues, one has to look pretty hard for information on small-sample or finite-size corrections for GLMMs: <span class="citation" data-cites="feng_small_2004">@feng_small_2004</span> and <span class="citation" data-cites="bell_small_2010">@bell_small_2010</span> look like good starting points, but it’s not at all trivial.</li>
</ul></li>
</ul>
<h4 id="df-alternatives">Df alternatives:</h4>
<ul>
<li>use MASS::glmmPQL (uses old <code>nlme</code> rules approximately equivalent to SAS ‘inner-outer’/‘within-between’ rules) for GLMMs, or <code>(n)lme</code> for LMMs</li>
<li>Guess the denominator df from standard rules (for standard designs, e.g. see <span class="citation" data-cites="GotelliEllison2004">@GotelliEllison2004</span>) and apply them to <span class="math inline">\(t\)</span> or <span class="math inline">\(F\)</span> tests</li>
<li>Run the model in <code>lme</code> (if possible) and use the denominator df reported there (which follow a simple ‘inner-outer’ rule which should correspond to the canonical answer for simple/orthogonal designs), applied to <span class="math inline">\(t\)</span> or <span class="math inline">\(F\)</span> tests. For the explicit specification of the rules that <code>lme</code> uses, see page 91 of Pinheiro and Bates (<em>this page was previously available on <a href="http://tinyurl.com/ntygq3">Google Books</a>, but the link is no longer useful, so here are the relevant paragraphs</em>):</li>
</ul>
<blockquote>
<p>These conditional tests for fixed-effects terms require denominator degrees of freedom. In the case of the conditional <span class="math inline">\(F\)</span>-tests, the numerator degrees of freedom are also required, being determined by the term itself. The denominator degrees of freedom are determined by the grouping level at which the term is estimated. A term is called inner relative to a factor if its value can change within a given level of the grouping factor. A term is outer to a grouping factor if its value does not changes within levels of the grouping factor. A term is said to be estimated at level <span class="math inline">\(i\)</span>, if it is inner to the <span class="math inline">\(i-1\)</span>st grouping factor and outer to the <span class="math inline">\(i\)</span>th grouping factor. For example, the term <code>Machine</code> in the <code>fm2Machine</code> model is outer to <code>Machine %in% Worker</code> and inner to <code>Worker</code>, so it is estimated at level 2 (<code>Machine %in% Worker</code>). If a term is inner to all <span class="math inline">\(Q\)</span> grouping factors in a model, it is estimated at the level of the within-group errors, which we denote as the <span class="math inline">\(Q+1\)</span>st level.</p>
<p>The intercept, which is the parameter corresponding to the column of all 1’s in the model matrices <span class="math inline">\(X_i\)</span>, is treated differently from all the other parameters, when it is present. As a parameter it is regarded as being estimated at level 0 because it is outer to all the grouping factors. However, its denominator degrees of freedom are calculated as if it were estimated at level <span class="math inline">\(Q+1\)</span>. This is because the intercept is the one parameter that pools information from all the observations at a level even when the corresponding column in <span class="math inline">\(X_i\)</span> doesn’t change with the level.</p>
<p>Letting <span class="math inline">\(m_i\)</span> denote the total number of groups in level <span class="math inline">\(i\)</span> (with the convention that <span class="math inline">\(m_0=1\)</span> when the fixed effects model includes an intercept and 0 otherwise, and <span class="math inline">\(m_{Q+1}=N\)</span>) and <span class="math inline">\(p_i\)</span> denote the sum of the degrees of freedom corresponding to the terms estimated at level <span class="math inline">\(i\)</span>, the <span class="math inline">\(i\)</span>th level denominator degrees of freedom is defined as</p>
<p><span class="math display">\[ \mathrm{denDF}_i = m_i - (m_{i-1} + p_i), i = 1, \dots, Q \]</span></p>
<p>This definition coincides with the classical decomposition of degrees of freedom in balanced, multilevel ANOVA designs and gives a reasonable approximation for more general mixed-effects models.</p>
</blockquote>
Note that the implementation used in <code>lme</code> <strong>gets the wrong answer for random-slopes models</strong>:
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://svn.r-project.org/R-packages/trunk/nlme'>nlme</a></span><span class='op'>)</span>
<span class='va'>lmeDF</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>formula</span><span class='op'>=</span><span class='va'>distance</span><span class='op'>~</span><span class='va'>age</span>,<span class='va'>random</span><span class='op'>=</span><span class='op'>~</span><span class='fl'>1</span><span class='op'>|</span><span class='va'>Subject</span><span class='op'>)</span> <span class='op'>{</span>
     <span class='va'>mod</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/nlme/man/lme.html'>lme</a></span><span class='op'>(</span><span class='va'>formula</span>,<span class='va'>random</span>,data<span class='op'>=</span><span class='va'>Orthodont</span><span class='op'>)</span>
     <span class='va'>aa</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/anova.html'>anova</a></span><span class='op'>(</span><span class='va'>mod</span><span class='op'>)</span>
    <span class='kw'><a href='https://rdrr.io/r/base/function.html'>return</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/stats/setNames.html'>setNames</a></span><span class='op'>(</span><span class='va'>aa</span><span class='op'>[</span>,<span class='st'>"denDF"</span><span class='op'>]</span>,<span class='fu'><a href='https://rdrr.io/r/base/colnames.html'>rownames</a></span><span class='op'>(</span><span class='va'>aa</span><span class='op'>)</span><span class='op'>)</span><span class='op'>)</span>
<span class='op'>}</span>
<span class='fu'>lmeDF</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>(Intercept)         age 
         80          80 </code></pre>
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'>lmeDF</span><span class='op'>(</span>random<span class='op'>=</span><span class='op'>~</span><span class='va'>age</span><span class='op'>|</span><span class='va'>Subject</span><span class='op'>)</span> <span class='co'>## wrong!</span>
</code></pre>
</div>
<pre><code>(Intercept)         age 
         80          80 </code></pre>
</div>
<p>I (BB) have re-implemented this algorithm in a way that does slightly better for random-slopes models (but may still get confused!), see <a href="R/calcDenDF.R">here</a>.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>home</span> <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/ifelse.html'>ifelse</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/Sys.info.html'>Sys.info</a></span><span class='op'>(</span><span class='op'>)</span><span class='op'>[</span><span class='st'>"sysname"</span><span class='op'>]</span> <span class='op'>==</span> <span class='st'>"Windows"</span>,
              <span class='fu'><a href='https://rdrr.io/r/base/Sys.getenv.html'>Sys.getenv</a></span><span class='op'>(</span><span class='st'>"USERPROFILE"</span><span class='op'>)</span>,
              <span class='fu'><a href='https://rdrr.io/r/base/Sys.getenv.html'>Sys.getenv</a></span><span class='op'>(</span><span class='st'>"HOME"</span><span class='op'>)</span><span class='op'>)</span>
<span class='va'>home</span> <span class='op'>=</span> <span class='va'>home</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://rdrr.io/r/base/grep.html'>gsub</a></span><span class='op'>(</span><span class='st'>"\\\\"</span>, <span class='st'>"/"</span>, <span class='va'>.</span><span class='op'>)</span>

<span class='va'>data_dir</span> <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/file.path.html'>file.path</a></span><span class='op'>(</span>
  <span class='va'>home</span>,
  <span class='st'>"Google Drive (basil.okola@student.uhasselt.be)"</span>,
  <span class='st'>"MSc. Stats Hasselt"</span>,
  <span class='st'>"y1 sem2"</span>,
  <span class='st'>"Multivariate and hierarchical data"</span>,
  <span class='st'>"sample size calculation"</span>
<span class='op'>)</span>
<span class='va'>site_dir</span> <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/file.path.html'>file.path</a></span><span class='op'>(</span><span class='va'>home</span>, <span class='st'>"Distill websites"</span>, <span class='st'>"_posts"</span><span class='op'>)</span>
<span class='va'>site_dir2</span> <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/file.path.html'>file.path</a></span><span class='op'>(</span><span class='va'>home</span>, <span class='st'>"Distill websites"</span><span class='op'>)</span>
<span class='kw'><a href='https://rdrr.io/r/base/source.html'>source</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/file.path.html'>file.path</a></span><span class='op'>(</span><span class='va'>site_dir</span>,<span class='st'>"2021-04-28-glmm-faq"</span>, <span class='st'>"calcDenDF.R"</span><span class='op'>)</span><span class='op'>)</span>
<span class='fu'>calcDenDF</span><span class='op'>(</span><span class='op'>~</span><span class='va'>age</span>,<span class='st'>"Subject"</span>,<span class='fu'>nlme</span><span class='fu'>::</span><span class='va'><a href='https://rdrr.io/pkg/nlme/man/Orthodont.html'>Orthodont</a></span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>(Intercept)         age 
         80          80 </code></pre>
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'>calcDenDF</span><span class='op'>(</span><span class='op'>~</span><span class='va'>age</span>,data<span class='op'>=</span><span class='fu'>nlme</span><span class='fu'>::</span><span class='va'><a href='https://rdrr.io/pkg/nlme/man/Orthodont.html'>Orthodont</a></span>,random<span class='op'>=</span><span class='op'>~</span><span class='fl'>1</span><span class='op'>|</span><span class='va'>Subject</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>(Intercept)         age 
         80          80 </code></pre>
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'>calcDenDF</span><span class='op'>(</span><span class='op'>~</span><span class='va'>age</span>,data<span class='op'>=</span><span class='fu'>nlme</span><span class='fu'>::</span><span class='va'><a href='https://rdrr.io/pkg/nlme/man/Orthodont.html'>Orthodont</a></span>,random<span class='op'>=</span><span class='op'>~</span><span class='va'>age</span><span class='op'>|</span><span class='va'>Subject</span><span class='op'>)</span> <span class='co'>## off by 1</span>
</code></pre>
</div>
<pre><code>(Intercept)         age 
         81          25 </code></pre>
</div>
<ul>
<li>use SAS, Genstat (AS-REML), Stata?</li>
<li>Assume infinite denominator df (i.e. <span class="math inline">\(Z\)</span>/<span class="math inline">\(\chi^2\)</span> test rather than <span class="math inline">\(t\)</span>/<span class="math inline">\(F\)</span>) if number of groups is large (&gt;45? Various rules of thumb for how large is “approximately infinite” have been posed, including <span class="citation" data-cites="angrist_mostly_2009">[in @angrist_mostly_2009]</span>, 42 (in homage to Douglas Adams)</li>
</ul>
<h3 id="testing-significance-of-random-effects">Testing significance of random effects</h3>
<ul>
<li>the most common way to do this is to use a likelihood ratio test, i.e. fit the full and reduced models (the reduced model is the model with the focal variance(s) set to zero). For example:
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://github.com/lme4/lme4/'>lme4</a></span><span class='op'>)</span>
<span class='va'>m2</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/lme4/man/lmer.html'>lmer</a></span><span class='op'>(</span><span class='va'>Reaction</span><span class='op'>~</span><span class='va'>Days</span><span class='op'>+</span><span class='op'>(</span><span class='fl'>1</span><span class='op'>|</span><span class='va'>Subject</span><span class='op'>)</span><span class='op'>+</span><span class='op'>(</span><span class='fl'>0</span><span class='op'>+</span><span class='va'>Days</span><span class='op'>|</span><span class='va'>Subject</span><span class='op'>)</span>,<span class='va'>sleepstudy</span>,REML<span class='op'>=</span><span class='cn'>FALSE</span><span class='op'>)</span>
<span class='va'>m1</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/update.html'>update</a></span><span class='op'>(</span><span class='va'>m2</span>,<span class='va'>.</span><span class='op'>~</span><span class='va'>Days</span><span class='op'>+</span><span class='op'>(</span><span class='fl'>1</span><span class='op'>|</span><span class='va'>Subject</span><span class='op'>)</span><span class='op'>)</span>
<span class='va'>m0</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/lm.html'>lm</a></span><span class='op'>(</span><span class='va'>Reaction</span><span class='op'>~</span><span class='va'>Days</span>,<span class='va'>sleepstudy</span><span class='op'>)</span>
<span class='fu'><a href='https://rdrr.io/r/stats/anova.html'>anova</a></span><span class='op'>(</span><span class='va'>m2</span>,<span class='va'>m1</span>,<span class='va'>m0</span><span class='op'>)</span> <span class='co'>## two sequential tests</span>
</code></pre>
</div></li>
</ul>
<pre><code>Data: sleepstudy
Models:
m0: Reaction ~ Days
m1: Reaction ~ Days + (1 | Subject)
m2: Reaction ~ Days + (1 | Subject) + (0 + Days | Subject)
   npar    AIC    BIC  logLik deviance   Chisq Df Pr(&gt;Chisq)    
m0    3 1906.3 1915.9 -950.15   1900.3                          
m1    4 1802.1 1814.8 -897.04   1794.1 106.214  1  &lt; 2.2e-16 ***
m2    5 1762.0 1778.0 -876.00   1752.0  42.075  1  8.782e-11 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
<p>With recent versions of <code>lme4</code>, goodness-of-fit (deviance) can be compared between <code>(g)lmer</code> and <code>(g)lm</code> models, although <code>anova()</code> must be called with the mixed (<code>(g)lmer</code>) model listed first. Keep in mind that LRT-based null hypothesis tests are conservative when the null value (such as <span class="math inline">\(\sigma^2=0\)</span>) is on the boundary of the feasible space <span class="citation" data-cites="self_asymptotic_1987 stram_variance_1994 GoldmanWhelan2000">[@self_asymptotic_1987;@stram_variance_1994;@GoldmanWhelan2000]</span>; in the simplest case (single random effect variance), the p-value is approximately twice as large as it should be <span class="citation" data-cites="pinheiro_mixed-effects_2000">[@pinheiro_mixed-effects_2000]</span>.</p>
<ul>
<li>Consider <em>not</em> testing the significance of random effects. If the random effect is part of the experimental design, this procedure may be considered ‘sacrificial pseudoreplication’ <span class="citation" data-cites="Hurlbert1984">[@Hurlbert1984]</span>. Using stepwise approaches to eliminate non-significant terms in order to squeeze more significance out of the remaining terms is dangerous in any case.</li>
<li>consider using the <code>RLRsim</code> package, which has a fast implementation of simulation-based tests of null hypotheses about zero variances, for simple tests. (However, it only applies to <code>lmer</code> models, and is a bit tricky to use for more complex models.)</li>
</ul>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://github.com/fabian-s/RLRsim'>RLRsim</a></span><span class='op'>)</span>
<span class='co'>## compare m0 and m1</span>
<span class='fu'><a href='https://rdrr.io/pkg/RLRsim/man/exactLRT.html'>exactLRT</a></span><span class='op'>(</span><span class='va'>m1</span>,<span class='va'>m0</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>
    simulated finite sample distribution of LRT. (p-value based
    on 10000 simulated values)

data:  
LRT = 106.21, p-value &lt; 2.2e-16</code></pre>
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'>## compare m1 and m2</span>
<span class='va'>mA</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/update.html'>update</a></span><span class='op'>(</span><span class='va'>m2</span>,REML<span class='op'>=</span><span class='cn'>TRUE</span><span class='op'>)</span>
<span class='va'>m0B</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/update.html'>update</a></span><span class='op'>(</span><span class='va'>mA</span>, <span class='va'>.</span> <span class='op'>~</span> <span class='va'>.</span> <span class='op'>-</span> <span class='op'>(</span><span class='fl'>0</span> <span class='op'>+</span> <span class='va'>Days</span><span class='op'>|</span><span class='va'>Subject</span><span class='op'>)</span><span class='op'>)</span>
<span class='va'>m.slope</span>  <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/update.html'>update</a></span><span class='op'>(</span><span class='va'>mA</span>, <span class='va'>.</span> <span class='op'>~</span> <span class='va'>.</span> <span class='op'>-</span> <span class='op'>(</span><span class='fl'>1</span><span class='op'>|</span><span class='va'>Subject</span><span class='op'>)</span><span class='op'>)</span>
<span class='fu'><a href='https://rdrr.io/pkg/RLRsim/man/exactRLRT.html'>exactRLRT</a></span><span class='op'>(</span>m0<span class='op'>=</span><span class='va'>m0B</span>,m<span class='op'>=</span><span class='va'>m.slope</span>,mA<span class='op'>=</span><span class='va'>mA</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>
    simulated finite sample distribution of RLRT.
    
    (p-value based on 10000 simulated values)

data:  
RLRT = 42.796, p-value &lt; 2.2e-16</code></pre>
</div>
<ul>
<li>Parametric bootstrap: fit the reduced model, then repeatedly simulate from it and compute the differences between the deviance of the reduced and the full model for each simulated data set. Compare this null distribution to the observed deviance difference. This procedure is implemented in the <code>pbkrtest</code> package (messages and warnings suppressed).
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='op'>(</span><span class='va'>pb</span> <span class='op'>&lt;-</span> <span class='fu'>pbkrtest</span><span class='fu'>::</span><span class='fu'><a href='https://rdrr.io/pkg/pbkrtest/man/pb-modcomp.html'>PBmodcomp</a></span><span class='op'>(</span><span class='va'>m2</span>,<span class='va'>m1</span>,seed<span class='op'>=</span><span class='fl'>101</span><span class='op'>)</span><span class='op'>)</span>
</code></pre>
</div></li>
</ul>
<pre><code>Bootstrap test; time: 53.98 sec; samples: 1000; extremes: 0;
Requested samples: 1000 Used samples: 500 Extremes: 0
large : Reaction ~ Days + (1 | Subject) + (0 + Days | Subject)
Reaction ~ Days + (1 | Subject)
         stat df   p.value    
LRT    42.075  1 8.782e-11 ***
PBtest 42.075     0.001996 ** 
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
<h3 id="standard-errors-of-variance-estimates">Standard errors of variance estimates</h3>
<p><a id="variance-standard-errors"></a></p>
<ul>
<li>Paraphrasing Doug Bates: the sampling distribution of variance estimates is in general strongly asymmetric: the standard error may be a poor characterization of the uncertainty.</li>
<li><code>lme4</code> allows for computing likelihood profiles of variances and computing confidence intervals on their basis; these likelihood profile confidence intervals are subject to the usual caveats about the LRT with finite sample sizes.</li>
<li>Using an MCMC-based approach (the simplest/most canned is probably to use the <code>MCMCglmm</code> package, although its mode specifications are not identical to those of lme4) will provide posterior distributions of the variance parameters: quantiles or credible intervals (<code>HPDinterval()</code> in the <code>coda</code> package) will characterize the uncertainty.</li>
<li>(don’t say we didn’t warn you …) <code>[n]lme</code> fits contain an element called <code>apVar</code> which contains the approximate variance-covariance matrix (derived from the Hessian, the matrix of (numerically approximated) second derivatives of the likelihood (REML?) at the maximum (restricted?) likelihood values): you can derive the standard errors from this list element via <code>sqrt(diag(lme.obj$apVar))</code>. For whatever it’s worth, though, <a href="http://www.biostat.wustl.edu/archives/html/s-news/2003-07/msg00127.html">these estimates might not match</a> the <a href="http://www.tau.ac.il/cc/pages/docs/sas8/stat/chap41/sect25.htm#mixedcpe">estimates that SAS gives</a> which are supposedly derived in the same way.</li>
<li>it’s not a full solution, but there is some more information <a href="https://rpubs.com/bbolker/waldvar">here</a>. I have some delta-method computations there that are off by a factor of 2 for the residual standard deviation, as well as some computations based on reparameterizing the deviance function.</li>
</ul>
<h3 id="p-values-mcmc-and-parametric-bootstrap">P-values: MCMC and parametric bootstrap</h3>
<p>Abandoning the approximate <span class="math inline">\(F\)</span>/<span class="math inline">\(t\)</span>-statistic route, one ends up with the more general problem of estimating <span class="math inline">\(p\)</span>-values. There is a wider range of options here, although many of them are computationally intensive …</p>
<h4 id="markov-chain-monte-carlo-sampling">Markov chain Monte Carlo sampling:</h4>
<ul>
<li>pseudo-Bayesian: post-hoc sampling, typically (1) assuming flat priors and (2) starting from the MLE, possibly using the approximate variance-covariance estimate to choose a candidate distribution
<ul>
<li>via <code>mcmcsamp</code> (if available for your problem: i.e. LMMs with simple random effects – not GLMMs or complex random effects)</li>
<li>via <code>pvals.fnc</code> in the <code>languageR</code> package, a wrapper for mcmcsamp)</li>
<li>in AD Model Builder, possibly via the <code>glmmADMB</code> package (use the <code>mcmc=TRUE</code> option) or the <code>R2admb</code> package (write your own model definition in AD Model Builder), or outside of R</li>
<li>via the <code>sim</code> function from the <code>arm</code> package (simulates the posterior only for the beta (fixed-effect) coefficients; not yet working with development lme4; would like a better formal description of the algorithm …?)</li>
</ul></li>
<li>fully Bayesian approaches
<ul>
<li>via the <code>MCMCglmm</code> package</li>
<li><code>glmmBUGS</code> (a WinBUGS wrapper/R interface)</li>
<li>JAGS/WinBUGS/OpenBUGS etc., via the <code>rjags</code>/<code>r2jags</code>/<code>R2WinBUGS</code>/<code>BRugs</code> packages</li>
</ul></li>
</ul>
<h4 id="status-of-mcmcsamp">Status of mcmcsamp</h4>
<p><code>mcmcsamp</code> is a function for lme4 that is supposed to sample from the posterior distribution of the parameters, based on flat/improper priors for the parameters [ed: I believe, but am not sure, that these priors are flat <strong>on the scale of the theta (Cholesky-factor) parameters</strong>]. At present, in the CRAN version (lme4 0.999999-0) and the R-forge “stable” version (lme4.0 0.999999-1), this covers only linear mixed models with uncorrelated random effects.</p>
<p>As has been discussed in a variety of places (e.g. <a href="http://article.gmane.org/gmane.comp.lang.r.lme4.devel/1788/">on r-sig-mixed models</a>, and <a href="https://r-forge.r-project.org/tracker/?func=detail&amp;aid=68&amp;group_id=60&amp;atid=298">on the r-forge bug tracker</a>, it is challenging to come up with a sampler that accounts properly for the possibility that the posterior distributions for some of the variance components may be mixtures of point masses at zero and continuous distributions. Naive samplers are likely to get stuck at or near zero. Doug Bates has always been a bit unsure that <code>mcmcsamp</code> is really performing as intended, even in the limited cases it now handles.</p>
<p>Given this uncertainty about how even the basic version works, the <code>lme4</code> developers have been reluctant to make the effort to extend it to GLMMs or more complex LMMs, or to implement it for the development version of lme4 … so unless something miraculous happens, it will not be implemented for the new version of <code>lme4</code>. As always, users are encouraged to write and share their own code that implements these capabilities …</p>
<h4 id="parametric-bootstrap">Parametric bootstrap</h4>
<p>The idea here is that in order to do inference on the effect of (a) predictor(s), you (1) fit the reduced model (without the predictors) to the data; (2) many times, (2a) simulate data from the reduced model; (2b) fit both the reduced and the full model to the simulated (null) data; (2c) compute some statistic(s) [e.g. t-statistic of the focal parameter, or the log-likelihood or deviance difference between the models]; (3) compare the observed values of the statistic from fitting your full model to the data to the null distribution generated in step 2. - <code>PBmodcomp</code> in the <code>pbkrtest</code> package - see the example in <code>help("simulate-mer")</code> in the <code>lme4</code> package to roll your own, using a combination of <code>simulate()</code> and <code>refit()</code>. - <code>bootMer</code> in <code>lme4</code> version &gt;1.0.0 - a presentation at UseR! 2009 (<a href="http://www.agrocampus-ouest.fr/math/useR-2009/abstracts/pdf/SanchezEspigares+Ocana.pdf">abstract</a>, <a href="http://www.agrocampus-ouest.fr/math/useR-2009/slides/SanchezEspigares+Ocana.pdf">slides</a>) went into detail about a proposed <code>bootMer</code> package and suggested it could work for GLMMs too – but it does not seem to be active.</p>
<h2 id="predictions-andor-confidence-or-prediction-intervals-on-predictions">Predictions and/or confidence (or prediction) intervals on predictions</h2>
<p>Note that none of the following approaches takes the uncertainty of the random effects parameters into account … if you want to take RE parameter uncertainty into account, a Bayesian approach is probably the easiest way to do it.</p>
<p>The general recipe for computing predictions from a linear or generalized linear model is to</p>
<ul>
<li>figure out the model matrix <span class="math inline">\(X\)</span> corresponding to the new data;</li>
<li>matrix-multiply <span class="math inline">\(X\)</span> by the parameter vector <span class="math inline">\(\beta\)</span> to get the predictions (or linear predictor in the case of GLM(M)s);</li>
<li>extract the variance-covariance matrix of the parameters <span class="math inline">\(V\)</span></li>
<li>compute <span class="math inline">\(X V X^{\prime}\)</span> to get the variance-covariance matrix of the predictions;</li>
<li>extract the diagonal of this matrix to get variances of predictions;</li>
<li>if computing prediction rather than confidence intervals, add the residual variance;</li>
<li>take the square-root of the variances to get the standard deviations (errors) of the predictions;</li>
<li>compute confidence intervals based on a Normal approximation;</li>
<li>for GL(M)Ms, run the confidence interval boundaries (not the standard errors) through the inverse-link function.</li>
</ul>
<h3 id="lme">lme</h3>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://svn.r-project.org/R-packages/trunk/nlme'>nlme</a></span><span class='op'>)</span> 
<span class='va'>fm1</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/nlme/man/lme.html'>lme</a></span><span class='op'>(</span><span class='va'>distance</span> <span class='op'>~</span> <span class='va'>age</span><span class='op'>*</span><span class='va'>Sex</span>, random <span class='op'>=</span> <span class='op'>~</span> <span class='fl'>1</span> <span class='op'>+</span> <span class='va'>age</span> <span class='op'>|</span> <span class='va'>Subject</span>,
           data <span class='op'>=</span> <span class='va'>Orthodont</span><span class='op'>)</span> 
<span class='fu'><a href='https://rdrr.io/r/graphics/plot.default.html'>plot</a></span><span class='op'>(</span><span class='va'>Orthodont</span>,asp<span class='op'>=</span><span class='st'>"fill"</span><span class='op'>)</span> <span class='co'>## plot responses by individual</span>
</code></pre>
</div>
<img src="glmm-faq_files/figure-html5/lmepred-1.png" width="624" />
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'>## note that expand.grid() orders factor levels by *order of</span>
<span class='co'>## appearance* -- must match levels(Orthodont$Sex)</span>
<span class='va'>newdat</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/expand.grid.html'>expand.grid</a></span><span class='op'>(</span>age<span class='op'>=</span><span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>8</span>,<span class='fl'>10</span>,<span class='fl'>12</span>,<span class='fl'>14</span><span class='op'>)</span>, Sex<span class='op'>=</span><span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='st'>"Female"</span>,<span class='st'>"Male"</span><span class='op'>)</span><span class='op'>)</span> 
<span class='va'>newdat</span><span class='op'>$</span><span class='va'>pred</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/predict.html'>predict</a></span><span class='op'>(</span><span class='va'>fm1</span>, <span class='va'>newdat</span>, level <span class='op'>=</span> <span class='fl'>0</span><span class='op'>)</span>

<span class='co'>## [-2] drops response from formula</span>
<span class='va'>Designmat</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/model.matrix.html'>model.matrix</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/stats/formula.html'>formula</a></span><span class='op'>(</span><span class='va'>fm1</span><span class='op'>)</span><span class='op'>[</span><span class='op'>-</span><span class='fl'>2</span><span class='op'>]</span>, <span class='va'>newdat</span><span class='op'>)</span>
<span class='va'>predvar</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/diag.html'>diag</a></span><span class='op'>(</span><span class='va'>Designmat</span> <span class='op'>%*%</span> <span class='fu'><a href='https://rdrr.io/r/stats/vcov.html'>vcov</a></span><span class='op'>(</span><span class='va'>fm1</span><span class='op'>)</span> <span class='op'>%*%</span> <span class='fu'><a href='https://rdrr.io/r/base/t.html'>t</a></span><span class='op'>(</span><span class='va'>Designmat</span><span class='op'>)</span><span class='op'>)</span> 
<span class='va'>newdat</span><span class='op'>$</span><span class='va'>SE</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/MathFun.html'>sqrt</a></span><span class='op'>(</span><span class='va'>predvar</span><span class='op'>)</span> 
<span class='va'>newdat</span><span class='op'>$</span><span class='va'>SE2</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/MathFun.html'>sqrt</a></span><span class='op'>(</span><span class='va'>predvar</span><span class='op'>+</span><span class='va'>fm1</span><span class='op'>$</span><span class='va'>sigma</span><span class='op'>^</span><span class='fl'>2</span><span class='op'>)</span>

<span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://ggplot2.tidyverse.org'>ggplot2</a></span><span class='op'>)</span> 
<span class='va'>pd</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://ggplot2.tidyverse.org/reference/position_dodge.html'>position_dodge</a></span><span class='op'>(</span>width<span class='op'>=</span><span class='fl'>0.4</span><span class='op'>)</span> 
<span class='va'>g0</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://ggplot2.tidyverse.org/reference/ggplot.html'>ggplot</a></span><span class='op'>(</span><span class='va'>newdat</span>,<span class='fu'><a href='https://ggplot2.tidyverse.org/reference/aes.html'>aes</a></span><span class='op'>(</span>x<span class='op'>=</span><span class='va'>age</span>,y<span class='op'>=</span><span class='va'>pred</span>,colour<span class='op'>=</span><span class='va'>Sex</span><span class='op'>)</span><span class='op'>)</span><span class='op'>+</span> 
   <span class='fu'><a href='https://ggplot2.tidyverse.org/reference/geom_point.html'>geom_point</a></span><span class='op'>(</span>position<span class='op'>=</span><span class='va'>pd</span><span class='op'>)</span>
<span class='va'>cmult</span> <span class='op'>&lt;-</span> <span class='fl'>2</span>  <span class='co'>## could use 1.96 instead</span>
<span class='va'>g0</span> <span class='op'>+</span> <span class='fu'><a href='https://ggplot2.tidyverse.org/reference/geom_linerange.html'>geom_linerange</a></span><span class='op'>(</span><span class='fu'><a href='https://ggplot2.tidyverse.org/reference/aes.html'>aes</a></span><span class='op'>(</span>ymin<span class='op'>=</span><span class='va'>pred</span><span class='op'>-</span><span class='va'>cmult</span><span class='op'>*</span><span class='va'>SE</span>,ymax<span class='op'>=</span><span class='va'>pred</span><span class='op'>+</span><span class='va'>cmult</span><span class='op'>*</span><span class='va'>SE</span><span class='op'>)</span>, position<span class='op'>=</span><span class='va'>pd</span><span class='op'>)</span>
</code></pre>
</div>
<img src="glmm-faq_files/figure-html5/lmepred-2.png" width="624" />
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'>## prediction intervals </span>
<span class='va'>g0</span> <span class='op'>+</span> <span class='fu'><a href='https://ggplot2.tidyverse.org/reference/geom_linerange.html'>geom_linerange</a></span><span class='op'>(</span><span class='fu'><a href='https://ggplot2.tidyverse.org/reference/aes.html'>aes</a></span><span class='op'>(</span>ymin<span class='op'>=</span><span class='va'>pred</span><span class='op'>-</span><span class='va'>cmult</span><span class='op'>*</span><span class='va'>SE2</span>,ymax<span class='op'>=</span><span class='va'>pred</span><span class='op'>+</span><span class='va'>cmult</span><span class='op'>*</span><span class='va'>SE2</span><span class='op'>)</span>, position<span class='op'>=</span><span class='va'>pd</span><span class='op'>)</span> 
</code></pre>
</div>
<p><img src="glmm-faq_files/figure-html5/lmepred-3.png" width="624" /></p>
</div>
<p>A similar answer is laid out in the responses to this <a href="http://stackoverflow.com/questions/14358811/extract-prediction-band-from-lme-fit">StackOverflow question</a>.</p>
<h3 id="lme4">lme4</h3>
<p>Current versions of lme4 have a <code>predict</code> method.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://github.com/lme4/lme4/'>lme4</a></span><span class='op'>)</span>
<span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://ggplot2.tidyverse.org'>ggplot2</a></span><span class='op'>)</span>
<span class='fu'><a href='https://rdrr.io/r/utils/data.html'>data</a></span><span class='op'>(</span><span class='st'>"Orthodont"</span>,package<span class='op'>=</span><span class='st'>"MEMSS"</span><span class='op'>)</span>
<span class='va'>fm1</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/lme4/man/lmer.html'>lmer</a></span><span class='op'>(</span>
  formula <span class='op'>=</span> <span class='va'>distance</span> <span class='op'>~</span> <span class='va'>age</span><span class='op'>*</span><span class='va'>Sex</span> <span class='op'>+</span> <span class='op'>(</span><span class='va'>age</span><span class='op'>|</span><span class='va'>Subject</span><span class='op'>)</span>
  , data <span class='op'>=</span> <span class='va'>Orthodont</span>
<span class='op'>)</span>
<span class='va'>newdat</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/expand.grid.html'>expand.grid</a></span><span class='op'>(</span>
  age<span class='op'>=</span><span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>8</span>,<span class='fl'>10</span>,<span class='fl'>12</span>,<span class='fl'>14</span><span class='op'>)</span>
  , Sex<span class='op'>=</span><span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='st'>"Female"</span>,<span class='st'>"Male"</span><span class='op'>)</span>
  , distance <span class='op'>=</span> <span class='fl'>0</span>
<span class='op'>)</span>
<span class='va'>newdat</span><span class='op'>$</span><span class='va'>distance</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/predict.html'>predict</a></span><span class='op'>(</span><span class='va'>fm1</span>,<span class='va'>newdat</span>,re.form<span class='op'>=</span><span class='cn'>NA</span><span class='op'>)</span>
<span class='va'>mm</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/model.matrix.html'>model.matrix</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/stats/terms.html'>terms</a></span><span class='op'>(</span><span class='va'>fm1</span><span class='op'>)</span>,<span class='va'>newdat</span><span class='op'>)</span>
<span class='co'>## or newdat$distance &lt;- mm %*% fixef(fm1)</span>
<span class='va'>pvar1</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/diag.html'>diag</a></span><span class='op'>(</span><span class='va'>mm</span> <span class='op'>%*%</span> <span class='fu'><a href='https://rdrr.io/r/base/crossprod.html'>tcrossprod</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/stats/vcov.html'>vcov</a></span><span class='op'>(</span><span class='va'>fm1</span><span class='op'>)</span>,<span class='va'>mm</span><span class='op'>)</span><span class='op'>)</span>
<span class='va'>tvar1</span> <span class='op'>&lt;-</span> <span class='va'>pvar1</span><span class='op'>+</span><span class='fu'><a href='https://rdrr.io/pkg/lme4/man/VarCorr.html'>VarCorr</a></span><span class='op'>(</span><span class='va'>fm1</span><span class='op'>)</span><span class='op'>$</span><span class='va'>Subject</span><span class='op'>[</span><span class='fl'>1</span><span class='op'>]</span>  <span class='co'>## must be adapted for more complex models</span>
<span class='va'>cmult</span> <span class='op'>&lt;-</span> <span class='fl'>2</span> <span class='co'>## could use 1.96</span>
<span class='va'>newdat</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/data.frame.html'>data.frame</a></span><span class='op'>(</span>
  <span class='va'>newdat</span>
  , plo <span class='op'>=</span> <span class='va'>newdat</span><span class='op'>$</span><span class='va'>distance</span><span class='op'>-</span><span class='va'>cmult</span><span class='op'>*</span><span class='fu'><a href='https://rdrr.io/r/base/MathFun.html'>sqrt</a></span><span class='op'>(</span><span class='va'>pvar1</span><span class='op'>)</span>
  , phi <span class='op'>=</span> <span class='va'>newdat</span><span class='op'>$</span><span class='va'>distance</span><span class='op'>+</span><span class='va'>cmult</span><span class='op'>*</span><span class='fu'><a href='https://rdrr.io/r/base/MathFun.html'>sqrt</a></span><span class='op'>(</span><span class='va'>pvar1</span><span class='op'>)</span>
  , tlo <span class='op'>=</span> <span class='va'>newdat</span><span class='op'>$</span><span class='va'>distance</span><span class='op'>-</span><span class='va'>cmult</span><span class='op'>*</span><span class='fu'><a href='https://rdrr.io/r/base/MathFun.html'>sqrt</a></span><span class='op'>(</span><span class='va'>tvar1</span><span class='op'>)</span>
  , thi <span class='op'>=</span> <span class='va'>newdat</span><span class='op'>$</span><span class='va'>distance</span><span class='op'>+</span><span class='va'>cmult</span><span class='op'>*</span><span class='fu'><a href='https://rdrr.io/r/base/MathFun.html'>sqrt</a></span><span class='op'>(</span><span class='va'>tvar1</span><span class='op'>)</span>
<span class='op'>)</span>
<span class='co'>#plot confidence</span>
<span class='va'>g0</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://ggplot2.tidyverse.org/reference/ggplot.html'>ggplot</a></span><span class='op'>(</span><span class='va'>newdat</span>, <span class='fu'><a href='https://ggplot2.tidyverse.org/reference/aes.html'>aes</a></span><span class='op'>(</span>x<span class='op'>=</span><span class='va'>age</span>, y<span class='op'>=</span><span class='va'>distance</span>, colour<span class='op'>=</span><span class='va'>Sex</span><span class='op'>)</span><span class='op'>)</span><span class='op'>+</span><span class='fu'><a href='https://ggplot2.tidyverse.org/reference/geom_point.html'>geom_point</a></span><span class='op'>(</span><span class='op'>)</span>
<span class='va'>g0</span> <span class='op'>+</span> <span class='fu'><a href='https://ggplot2.tidyverse.org/reference/geom_linerange.html'>geom_pointrange</a></span><span class='op'>(</span><span class='fu'><a href='https://ggplot2.tidyverse.org/reference/aes.html'>aes</a></span><span class='op'>(</span>ymin <span class='op'>=</span> <span class='va'>plo</span>, ymax <span class='op'>=</span> <span class='va'>phi</span><span class='op'>)</span><span class='op'>)</span><span class='op'>+</span>
    <span class='fu'><a href='https://ggplot2.tidyverse.org/reference/labs.html'>labs</a></span><span class='op'>(</span>title<span class='op'>=</span><span class='st'>"CI based on fixed-effects uncertainty ONLY"</span><span class='op'>)</span>
</code></pre>
</div>
<img src="glmm-faq_files/figure-html5/lme4pred-1.png" width="624" />
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'>#plot prediction</span>
<span class='va'>g0</span> <span class='op'>+</span> <span class='fu'><a href='https://ggplot2.tidyverse.org/reference/geom_linerange.html'>geom_pointrange</a></span><span class='op'>(</span><span class='fu'><a href='https://ggplot2.tidyverse.org/reference/aes.html'>aes</a></span><span class='op'>(</span>ymin <span class='op'>=</span> <span class='va'>tlo</span>, ymax <span class='op'>=</span> <span class='va'>thi</span><span class='op'>)</span><span class='op'>)</span><span class='op'>+</span>
    <span class='fu'><a href='https://ggplot2.tidyverse.org/reference/labs.html'>labs</a></span><span class='op'>(</span>title<span class='op'>=</span><span class='st'>"CI based on FE uncertainty + RE variance"</span><span class='op'>)</span>
</code></pre>
</div>
<img src="glmm-faq_files/figure-html5/lme4pred-2.png" width="624" />
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/rm.html'>rm</a></span><span class='op'>(</span><span class='st'>"Orthodont"</span><span class='op'>)</span> <span class='co'>## clean up</span>
</code></pre>
</div>
</div>
<h3 id="glmmtmb">glmmTMB</h3>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://github.com/glmmTMB/glmmTMB'>glmmTMB</a></span><span class='op'>)</span>
<span class='fu'><a href='https://rdrr.io/r/utils/data.html'>data</a></span><span class='op'>(</span><span class='va'>Orthodont</span>,package<span class='op'>=</span><span class='st'>"nlme"</span><span class='op'>)</span>
<span class='va'>fm2</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/glmmTMB/man/glmmTMB.html'>glmmTMB</a></span><span class='op'>(</span><span class='va'>distance</span> <span class='op'>~</span> <span class='va'>age</span><span class='op'>*</span><span class='va'>Sex</span> <span class='op'>+</span> <span class='op'>(</span><span class='va'>age</span> <span class='op'>|</span> <span class='va'>Subject</span><span class='op'>)</span>,
                data <span class='op'>=</span> <span class='va'>Orthodont</span>,
                family<span class='op'>=</span><span class='st'>"gaussian"</span><span class='op'>)</span>

<span class='co'>## make prediction data frame</span>
<span class='va'>newdat</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/expand.grid.html'>expand.grid</a></span><span class='op'>(</span>age<span class='op'>=</span><span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>8</span>,<span class='fl'>10</span>,<span class='fl'>12</span>,<span class='fl'>14</span><span class='op'>)</span>, Sex<span class='op'>=</span><span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='st'>"Female"</span>,<span class='st'>"Male"</span><span class='op'>)</span><span class='op'>)</span>
<span class='co'>## design matrix (fixed effects)</span>
<span class='va'>mm</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/model.matrix.html'>model.matrix</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/stats/delete.response.html'>delete.response</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/stats/terms.html'>terms</a></span><span class='op'>(</span><span class='va'>fm2</span><span class='op'>)</span><span class='op'>)</span>,<span class='va'>newdat</span><span class='op'>)</span>
<span class='co'>## linear predictor (for GLMMs, back-transform this with the</span>
<span class='co'>##  inverse link function (e.g. plogis() for binomial, beta;</span>
<span class='co'>##  exp() for Poisson, negative binomial</span>
<span class='va'>newdat</span><span class='op'>$</span><span class='va'>distance</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/drop.html'>drop</a></span><span class='op'>(</span><span class='va'>mm</span> <span class='op'>%*%</span> <span class='fu'><a href='https://rdrr.io/pkg/glmmTMB/man/fixef.html'>fixef</a></span><span class='op'>(</span><span class='va'>fm2</span><span class='op'>)</span><span class='op'>[[</span><span class='st'>"cond"</span><span class='op'>]</span><span class='op'>]</span><span class='op'>)</span>
<span class='va'>predvar</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/diag.html'>diag</a></span><span class='op'>(</span><span class='va'>mm</span> <span class='op'>%*%</span> <span class='fu'><a href='https://rdrr.io/r/stats/vcov.html'>vcov</a></span><span class='op'>(</span><span class='va'>fm2</span><span class='op'>)</span><span class='op'>[[</span><span class='st'>"cond"</span><span class='op'>]</span><span class='op'>]</span> <span class='op'>%*%</span> <span class='fu'><a href='https://rdrr.io/r/base/t.html'>t</a></span><span class='op'>(</span><span class='va'>mm</span><span class='op'>)</span><span class='op'>)</span>
<span class='va'>newdat</span><span class='op'>$</span><span class='va'>SE</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/MathFun.html'>sqrt</a></span><span class='op'>(</span><span class='va'>predvar</span><span class='op'>)</span> 
<span class='va'>newdat</span><span class='op'>$</span><span class='va'>SE2</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/MathFun.html'>sqrt</a></span><span class='op'>(</span><span class='va'>predvar</span><span class='op'>+</span><span class='fu'><a href='https://rdrr.io/pkg/glmmTMB/man/sigma.glmmTMB.html'>sigma</a></span><span class='op'>(</span><span class='va'>fm2</span><span class='op'>)</span><span class='op'>^</span><span class='fl'>2</span><span class='op'>)</span>
</code></pre>
</div>
</div>
(Probably overly complicated) <code>ggplot</code> code:
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://ggplot2.tidyverse.org'>ggplot2</a></span><span class='op'>)</span>;  <span class='fu'><a href='https://ggplot2.tidyverse.org/reference/theme_get.html'>theme_set</a></span><span class='op'>(</span><span class='fu'><a href='https://ggplot2.tidyverse.org/reference/ggtheme.html'>theme_bw</a></span><span class='op'>(</span><span class='op'>)</span><span class='op'>)</span>
<span class='va'>pd</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://ggplot2.tidyverse.org/reference/position_dodge.html'>position_dodge</a></span><span class='op'>(</span>width<span class='op'>=</span><span class='fl'>0.4</span><span class='op'>)</span>
<span class='va'>g0</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://ggplot2.tidyverse.org/reference/ggplot.html'>ggplot</a></span><span class='op'>(</span><span class='va'>Orthodont</span>,<span class='fu'><a href='https://ggplot2.tidyverse.org/reference/aes.html'>aes</a></span><span class='op'>(</span>x<span class='op'>=</span><span class='va'>age</span>,y<span class='op'>=</span><span class='va'>distance</span>,colour<span class='op'>=</span><span class='va'>Sex</span><span class='op'>)</span><span class='op'>)</span><span class='op'>+</span>
    <span class='fu'><a href='https://ggplot2.tidyverse.org/reference/geom_count.html'>stat_sum</a></span><span class='op'>(</span>alpha<span class='op'>=</span><span class='fl'>0.2</span>,<span class='fu'><a href='https://ggplot2.tidyverse.org/reference/aes.html'>aes</a></span><span class='op'>(</span>size<span class='op'>=</span><span class='va'>..n..</span><span class='op'>)</span><span class='op'>)</span><span class='op'>+</span>
    <span class='fu'><a href='https://ggplot2.tidyverse.org/reference/scale_size.html'>scale_size_continuous</a></span><span class='op'>(</span>breaks<span class='op'>=</span><span class='fl'>1</span><span class='op'>:</span><span class='fl'>4</span>,range<span class='op'>=</span><span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>2</span>,<span class='fl'>5</span><span class='op'>)</span><span class='op'>)</span>
<span class='va'>g1</span> <span class='op'>&lt;-</span> <span class='va'>g0</span><span class='op'>+</span><span class='fu'><a href='https://ggplot2.tidyverse.org/reference/geom_path.html'>geom_line</a></span><span class='op'>(</span>data<span class='op'>=</span><span class='va'>newdat</span>,position<span class='op'>=</span><span class='va'>pd</span><span class='op'>)</span><span class='op'>+</span>
    <span class='fu'><a href='https://ggplot2.tidyverse.org/reference/geom_point.html'>geom_point</a></span><span class='op'>(</span>data<span class='op'>=</span><span class='va'>newdat</span>,shape<span class='op'>=</span><span class='fl'>17</span>,size<span class='op'>=</span><span class='fl'>3</span>,position<span class='op'>=</span><span class='va'>pd</span><span class='op'>)</span>
<span class='co'>## confidence intervals</span>
<span class='va'>g2</span> <span class='op'>&lt;-</span> <span class='va'>g1</span> <span class='op'>+</span> <span class='fu'><a href='https://ggplot2.tidyverse.org/reference/geom_linerange.html'>geom_linerange</a></span><span class='op'>(</span>data<span class='op'>=</span><span class='va'>newdat</span>,
                          <span class='fu'><a href='https://ggplot2.tidyverse.org/reference/aes.html'>aes</a></span><span class='op'>(</span>ymin<span class='op'>=</span><span class='va'>distance</span><span class='op'>-</span><span class='fl'>2</span><span class='op'>*</span><span class='va'>SE</span>,ymax<span class='op'>=</span><span class='va'>distance</span><span class='op'>+</span><span class='fl'>2</span><span class='op'>*</span><span class='va'>SE</span><span class='op'>)</span>,
                          lwd<span class='op'>=</span><span class='fl'>2</span>, position<span class='op'>=</span><span class='va'>pd</span><span class='op'>)</span>
<span class='co'>## prediction intervals </span>
<span class='va'>g2</span> <span class='op'>+</span> <span class='fu'><a href='https://ggplot2.tidyverse.org/reference/geom_linerange.html'>geom_linerange</a></span><span class='op'>(</span>data<span class='op'>=</span><span class='va'>newdat</span>,
                    <span class='fu'><a href='https://ggplot2.tidyverse.org/reference/aes.html'>aes</a></span><span class='op'>(</span>ymin<span class='op'>=</span><span class='va'>distance</span><span class='op'>-</span><span class='fl'>2</span><span class='op'>*</span><span class='va'>SE2</span>,ymax<span class='op'>=</span><span class='va'>distance</span><span class='op'>+</span><span class='fl'>2</span><span class='op'>*</span><span class='va'>SE2</span><span class='op'>)</span>, position<span class='op'>=</span><span class='va'>pd</span><span class='op'>)</span>
</code></pre>
</div>
<p><img src="glmm-faq_files/figure-html5/ggplot-1.png" width="624" /></p>
</div>
<p>The <code>effects</code>, <code>emmeans</code>, and <code>sjPlot</code> packages are also useful here.</p>
<h2 id="confidence-intervals-on-conditional-meansblupsrandom-effects">Confidence intervals on conditional means/BLUPs/random effects</h2>
<h3 id="lme4-1">lme4</h3>
<p>(From Harold Doran, updated by Assaf Oron Nov. 2013:)</p>
If you want the standard errors of the conditional means, you can extract them as follows:
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://github.com/lme4/lme4/'>lme4</a></span><span class='op'>)</span>
<span class='va'>fm1</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/lme4/man/lmer.html'>lmer</a></span><span class='op'>(</span><span class='va'>Reaction</span> <span class='op'>~</span> <span class='va'>Days</span> <span class='op'>+</span> <span class='op'>(</span><span class='va'>Days</span><span class='op'>|</span><span class='va'>Subject</span><span class='op'>)</span>, <span class='va'>sleepstudy</span><span class='op'>)</span>
<span class='va'>cV</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/lme4/man/ranef.html'>ranef</a></span><span class='op'>(</span><span class='va'>fm1</span>, condVar <span class='op'>=</span> <span class='cn'>TRUE</span><span class='op'>)</span>   
</code></pre>
</div>
</div>
<p><code>cV</code> is a list; each element is a data frame containing the conditional modes for a particular grouping factor. If you use scalar random effects (typically random intercepts), then specifying <code>ranef(...,drop=TRUE)</code> will return the conditional modes as a single named vector instead.</p>
<p>The conditional variances are returned as an attribute of the conditional modes. It may be easiest to use <code>as.data.frame(cV)</code>, or <code>broom.mixed::tidy(fm1, effects="ran_vals")</code>, to extract all of the conditional means and standard deviations.</p>
Or, digging in to the data structure by hand: if we set
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>ranvar</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/attr.html'>attr</a></span><span class='op'>(</span><span class='va'>cV</span><span class='op'>[[</span><span class='fl'>1</span><span class='op'>]</span><span class='op'>]</span>, <span class='st'>"postVar"</span><span class='op'>)</span>
</code></pre>
</div>
</div>
then <code>ranvar</code> is a 3-D array (the attribute is still called <code>postVar</code>, rather than <code>condVar</code>, for historical reasons/backward compatibility). Individual-level covariance matrices of the conditional modes will sit on the <code>[,,i]</code> faces. For example, <code>ranvar[,,1]</code> is the variance-covariance matrix of the conditional distribution for the first group, so
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/MathFun.html'>sqrt</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/diag.html'>diag</a></span><span class='op'>(</span><span class='va'>ranvar</span><span class='op'>[</span>,,<span class='fl'>1</span><span class='op'>]</span><span class='op'>)</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>[1] 12.070857  2.304839</code></pre>
</div>
will provide the intercept and slope standard standard deviations for the first group’s conditional modes. If you have a scalar random effect and used <code>drop=TRUE</code> in <code>ranef()</code>, then you will (mercifully) receive only a vector of individual variances here (one for each level of the grouping factor). The following incantation will give a matrix of conditional variances with one row for each group and one column for each parameters:
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>ng</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/dim.html'>dim</a></span><span class='op'>(</span><span class='va'>ranvar</span><span class='op'>)</span><span class='op'>[</span><span class='fl'>3</span><span class='op'>]</span>
<span class='va'>np</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/dim.html'>dim</a></span><span class='op'>(</span><span class='va'>ranvar</span><span class='op'>)</span><span class='op'>[</span><span class='fl'>2</span><span class='op'>]</span>
<span class='va'>mm</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/matrix.html'>matrix</a></span><span class='op'>(</span><span class='va'>ranvar</span><span class='op'>[</span><span class='fu'><a href='https://rdrr.io/r/base/cbind.html'>cbind</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/rep.html'>rep</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/seq.html'>seq</a></span><span class='op'>(</span><span class='va'>np</span><span class='op'>)</span>,<span class='va'>ng</span><span class='op'>)</span>,
             <span class='fu'><a href='https://rdrr.io/r/base/rep.html'>rep</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/seq.html'>seq</a></span><span class='op'>(</span><span class='va'>np</span><span class='op'>)</span>,<span class='va'>ng</span><span class='op'>)</span>,
             <span class='fu'><a href='https://rdrr.io/r/base/rep.html'>rep</a></span><span class='op'>(</span><span class='va'>ng</span>,each<span class='op'>=</span><span class='va'>np</span><span class='op'>)</span><span class='op'>)</span><span class='op'>]</span>,
       byrow<span class='op'>=</span><span class='cn'>TRUE</span>,
       nrow<span class='op'>=</span><span class='va'>ng</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<p>Getting the uncertainty of the coefficients (i.e., what’s returned by <code>coef()</code>: the sum of the fixed-effect and random-effect predictions for a particular level) is not (alas) currently easy with <code>lme4</code>. If the fixed and random effects were independent then we could simply add the conditional variance and the variance of the fixed-effect predictions, but they aren’t in general. There is a long <a href="https://stat.ethz.ch/pipermail/r-sig-mixed-models/2013q1/019795.html">r-sig-mixed-models mailing list thread</a> that discusses the issues, focusing on (1) how to extract the covariance between fixed-effect estimate and the random-effect prediction; (2) whether this value (the covariance between an <em>estimated</em> parameter and a <em>predicted</em> mode of a conditional distribution of a random variable) even makes sense in a frequentist framework. If you’re willing to <em>assume</em> independence of the conditional variance and the fixed-effect sampling variance, then (e.g.) the variance of the intercepts for each group would be the sum of the fixed-effect intercept variance and the conditional variance of the intercept for each group:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/stats/vcov.html'>vcov</a></span><span class='op'>(</span><span class='va'>fm1</span><span class='op'>)</span><span class='op'>[</span><span class='fl'>1</span>,<span class='fl'>1</span><span class='op'>]</span><span class='op'>+</span><span class='va'>mm</span><span class='op'>[</span>,<span class='fl'>1</span><span class='op'>]</span>
</code></pre>
</div>
<pre><code> [1] 192.2807 192.2807 192.2807 192.2807 192.2807 192.2807 192.2807
 [8] 192.2807 192.2807 192.2807 192.2807 192.2807 192.2807 192.2807
[15] 192.2807 192.2807 192.2807 192.2807</code></pre>
</div>
<h2 id="power-analysis">Power analysis</h2>
<p>Power analysis for (G)LMMs is mostly done by simulation, although there are some closed-form solutions and approximations, e.g. <span class="citation" data-cites="snijders_standard_1993">@snijders_standard_1993</span> (Snijders has links to programs and other resources on <a href="https://www.stats.ox.ac.uk/~snijders/multilevel.htm">his web page</a>). There are resources and bits of code examples spread all over the internet. e.g. <a href="https://rpubs.com/bbolker/11703">here</a>.</p>
<p><span class="citation" data-cites="kain_practical_2015">@kain_practical_2015</span> and <span class="citation" data-cites="johnson_power_2015">@johnson_power_2015</span> are peer-reviewed papers that discuss power analysis via simulation in more detail.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'>sos</span><span class='op'>)</span>; <span class='fu'><a href='https://rdrr.io/pkg/sos/man/findFn.html'>findFn</a></span><span class='op'>(</span><span class='st'>"{power analysis} mixed simulation"</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<p>locates the <code>fullfact</code>, <code>pamm</code>, <code>simr</code>, and <code>simglm</code> packages. Depending on the goal, one of these packages may have sufficient flexibility to do what you want.</p>
<h1 id="model-selection-and-averaging">Model selection and averaging</h1>
<h2 id="can-i-use-aic-for-mixed-models-how-do-i-count-the-number-of-degrees-of-freedom-for-a-random-effect">Can I use AIC for mixed models? How do I count the number of degrees of freedom for a random effect?</h2>
<ul>
<li>Yes, with caution.</li>
<li>It depends on the “level of focus” (<em>sensu</em> <span class="citation" data-cites="spiegelhalter_bayesian_2002">@spiegelhalter_bayesian_2002</span>) whether (e.g.) a single random-effect variance should be counted as 1 degree of freedom (i.e., the variance parameter or as a value between 1 and N-1 (where N is the number of groups): see <span class="citation" data-cites="vaida_conditional_2005">@vaida_conditional_2005</span> and <span class="citation" data-cites="greven_behaviour_2010">@greven_behaviour_2010</span>. If you are interested in population-level prediction/inference, then the former (called <em>marginal AIC</em> [mAIC]); if individual-level prediction/inference (i.e., using the BLUPs/conditional modes), then the latter (called <em>conditional AIC</em> [cAIC]). Greven and Kneib present results for linear models, giving a version of cAIC that is both computationally efficient and takes uncertainty in the estimation of the variances into account. (Bob O’Hara has a very nice, illustrative <a href="http://deepthoughtsandsilliness.blogspot.ca/2007/12/focus-on-dic.html">blog post</a> on this topic in the context of DIC …)</li>
<li>in cases when testing a variance parameter, AIC may be subject to the same kinds of boundary effects as likelihood ratio test p-values (i.e., AICs may be conservative/overfit slightly when the nested parameter value is on the boundary of the feasible space). <span class="citation" data-cites="greven_behaviour_2010">@greven_behaviour_2010</span> explore the problems with mAIC in this context, but do not suggest a solution (they point out that <span class="citation" data-cites="hughes_model_2003">@hughes_model_2003</span> present a ‘one-sided’ AIC, but not one that deals with the non-independence of data points. I haven’t read Hughes and King, I should go do that).</li>
<li>AIC also inherits the primary problem of likelihood ratio tests in the GLMM context – that is, that LRTs are asymptotic tests. A finite-size correction for AIC does exist (AICc) – but it was developed in the context of linear models. As far as I know its adequacy in the GLMM case has not been established. See e.g. <span class="citation" data-cites="richards_testing_2005">@richards_testing_2005</span> for caution about AICc in the GLM (not GLMM) case.</li>
<li>lme4 and nlme count parameters for AIC(c) as follows:
<ul>
<li>the number of fixed-effect parameters is straightforward (the length of the fixed-effect parameter vector beta, i.e. <code>length(fixef(model))</code>)</li>
<li>each random term in the model with <span class="math inline">\(q\)</span> components counts for <span class="math inline">\(q(q+1)/2\)</span> parameters – for example, a term of the form (slope|group) has 3 parameters (intercept variance, slope variance, correlation between intercept and slope).</li>
<li>models that use a scale parameter (e.g. the variance parameter of linear mixed models, or the scale parameter of a Gamma GLMM – standard GLMMs such as binomial and Poisson do not) get an extra parameter counted. Whether to add nuisance parameters or not, such as the residual variance parameter (estimated based on the residual variance, rather than an explicit parameter in the optimization) is as far as I know an open question. In the classic AIC context it doesn’t matter as long as one is consistent. In the AICc context, I don’t think anyone really knows the answer … adding +1 for the residual variance parameter (as lme4 does) would make the model selection process slightly more conservative.</li>
</ul></li>
</ul>
<h1 id="model-summaries-goodness-of-fit-decomposition-of-variance-etc.">Model summaries (goodness-of-fit, decomposition of variance, etc.)</h1>
<h2 id="how-do-i-compute-a-coefficient-of-determination-r2-or-an-analogue-for-glmms">How do I compute a coefficient of determination (<span class="math inline">\(R^2\)</span>), or an analogue, for (G)LMMs?</h2>
<h3 id="problem">Problem</h3>
<p>(<em>This topic applies to both LMMs and GLMMs, perhaps more so to LMMs, because the issues are even harder for GLMMs.</em>)</p>
<p>Researchers often want to know if there is a simple (or at least implemented-in-R) way to get an analogue of <span class="math inline">\(R^2\)</span> or another simple goodness-of-fit metric for LMMs or GLMMs. This is a challenging question in both the GLM and LMM worlds (and therefore doubly so for GLMMs), because it turns out that the wonderful simplicity of <span class="math inline">\(R^2\)</span> breaks down in the extension to GLMs or LMMs. If you’re trying to quantify “fraction of variance explained” in the GLM context, should you include or exclude sampling variation (e.g., Poisson variation around the expected mean)? [According to an <code>sos::findFn</code> search for “Nagelkerke”, one of the common solutions to this problem, the <code>LogRegR2</code> function in the <code>descr</code> package computes several different “pseudo-<span class="math inline">\(R^2\)</span>” measures for logistic regression.] If you’re trying to quantify it in the LMM context, should you include or exclude variation of different random-effects terms?</p>
<p>The same questions apply more generally to decomposition of variance (i.e. trying to assess the contribution of various model components to the overall fit, not just trying to assess the overall goodness-of-fit of the model); there is unlikely to be a single recipe that does everything you want.</p>
<p>This has been discussed at various times on the mailing lists. <a href="http://thread.gmane.org/gmane.comp.lang.r.lme4.devel/3281">This thread</a> and <a href="http://thread.gmane.org/gmane.comp.lang.r.lme4.devel/684">this thread</a> on the r-sig-mixed-models mailing list are good starting points, and <a href="http://thread.gmane.org/gmane.comp.lang.r.lme4.devel/2143">this post</a> is useful too.</p>
<p>In one of those threads, Doug Bates said:</p>
<blockquote>
<p>Assuming that one wants to define an R^2 measure, I think an argument could be made for treating the penalized residual sum of squares from a linear mixed model in the same way that we consider the residual sum of squares from a linear model. Or one could use just the residual sum of squares without the penalty or the minimum residual sum of squares obtainable from a given set of terms, which corresponds to an infinite precision matrix. I don’t know, really. It depends on what you are trying to characterize.</p>
</blockquote>
<h3 id="simplecrude-solutions">Simple/crude solutions</h3>
In one of those threads, Jarrett Byrnes contributed the following code:
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>r2.corr.mer</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>m</span><span class='op'>)</span> <span class='op'>{</span>
   <span class='va'>lmfit</span> <span class='op'>&lt;-</span>  <span class='fu'><a href='https://rdrr.io/r/stats/lm.html'>lm</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/stats/model.extract.html'>model.response</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/stats/model.frame.html'>model.frame</a></span><span class='op'>(</span><span class='va'>m</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>~</span> <span class='fu'><a href='https://rdrr.io/r/stats/fitted.values.html'>fitted</a></span><span class='op'>(</span><span class='va'>m</span><span class='op'>)</span><span class='op'>)</span>
   <span class='fu'><a href='https://rdrr.io/r/base/summary.html'>summary</a></span><span class='op'>(</span><span class='va'>lmfit</span><span class='op'>)</span><span class='op'>$</span><span class='va'>r.squared</span>
<span class='op'>}</span>
</code></pre>
</div>
</div>
<p><span class="math inline">\(\Omega^2_0\)</span> <span class="citation" data-cites="xu_measuring_2003">[@xu_measuring_2003]</span>, which is almost the same, is based on comparing the residual variance of the full model against the residual variance of a (fixed) intercept-only null model:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fl'>1</span><span class='op'>-</span><span class='fu'><a href='https://rdrr.io/r/stats/cor.html'>var</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/stats/residuals.html'>residuals</a></span><span class='op'>(</span><span class='va'>m</span><span class='op'>)</span><span class='op'>)</span><span class='op'>/</span><span class='fu'><a href='https://rdrr.io/r/stats/cor.html'>var</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/stats/model.extract.html'>model.response</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/stats/model.frame.html'>model.frame</a></span><span class='op'>(</span><span class='va'>m</span><span class='op'>)</span><span class='op'>)</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<p>Another possibility is the squared correlation between the response variable and the predicted values:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/stats/cor.html'>cor</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/stats/model.extract.html'>model.response</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/stats/model.frame.html'>model.frame</a></span><span class='op'>(</span><span class='va'>m</span><span class='op'>)</span><span class='op'>)</span>,<span class='fu'><a href='https://rdrr.io/r/stats/predict.html'>predict</a></span><span class='op'>(</span><span class='va'>m</span>,type<span class='op'>=</span><span class='st'>"response"</span><span class='op'>)</span><span class='op'>)</span><span class='op'>^</span><span class='fl'>2</span>
</code></pre>
</div>
</div>
<h3 id="sophisticated-solutions">Sophisticated solutions</h3>
<p><span class="citation" data-cites="gelman_bayesian_2006">@gelman_bayesian_2006</span> propose/discuss Bayesian measures of <span class="math inline">\(R^2\)</span> (I don’t know if anyone has created a canned implementation of these measures in R). <span class="citation" data-cites="nakagawa_general_2013">@nakagawa_general_2013</span> and <span class="citation" data-cites="johnson_extension_2014">@johnson_extension_2014</span> have also proposed a general methodology for computing <span class="math inline">\(R^2\)</span>; J. Lefcheck gives examples <a href="https://jonlefcheck.net/2013/03/13/r2-for-linear-mixed-effects-models/">here</a> and <a href="https://github.com/jslefche/piecewiseSEM/blob/master/README.md#get-r2-for-individual-models">here</a>, based on his implementation in the <code>piecewiseSEM</code> package (<a href="https://cran.r-project.org/web/packages/piecewiseSEM/index.html">CRAN</a>, <a href="https://github.com/jslefche/piecewiseSEM">Github</a>). See also <span class="citation" data-cites="jaeger_r2_2017">@jaeger_r2_2017</span>, <span class="citation" data-cites="rights_quantifying_2018">@rights_quantifying_2018</span> …</p>
<p>A related question is how to quantify “repeatability” (i.e., ratios of variance at different levels) in GLMMs, especially how to compute the “residual error” term for GLMMs: see <span class="citation" data-cites="nakagawa_repeatability_2010">@nakagawa_repeatability_2010</span> and the <a href="http://rptr.r-forge.r-project.org/">rptR package</a>.</p>
<p>The bottom line is that there are some simple recipes (and some more complex recipes that may or may not have been coded up by someone), but that ’‘’you have to think carefully about what information you want to get out of the coefficient of determination’’’, because no recipe will have all of the properties of <span class="math inline">\(R^2\)</span> in the simple linear model case.</p>
<p><strong>Packages/functions</strong>: See <a href="https://easystats.github.io/performance/reference/r2.html"><code>performance::r2()</code></a>, <code>MuMIn::r.squaredGLMM()</code>, the <a href="https://CRAN.R-project.org/package=r2glmm"><code>r2glmm</code> package</a>, the standalone <a href="https://my.vanderbilt.edu/jasonrights/software/r2MLM">r2MLM function</a>, stuff in the <code>piecewiseSEM</code> package, <a href="http://finzi.psych.upenn.edu/R/library/psycho/html/R2_nakagawa.html"><code>psycho::R2_nakagawa</code></a>, <a href="https://github.com/mastoffel/partR2">partR2</a> package … (try e.g. <code>sos::findFn("Nakagawa Schielzeth")</code> for an up-to-date list …)</p>
<h2 id="variable-importance">Variable importance</h2>
<ul>
<li><p>The simplest way to get (within-study) measures of variable importance is to standardize the predictor variables (scaling by 1 SD or 2SD: <span class="citation" data-cites="gelman_scaling_2008">@gelman_scaling_2008</span>, <span class="citation" data-cites="schielzeth_simple_2010">@schielzeth_simple_2010</span>)</p></li>
<li><p>The <code>r2glmm</code> package computes partial <span class="math inline">\(R^2\)</span> values for fixed effects (only for <code>lmer</code>, <code>lme</code>, and <code>glmmPQL</code> models)</p></li>
<li><p>Henrik Singmann has a detailed answer <a href="https://afex.singmann.science/forums/topic/compute-effect-sizes-for-mixed-objects">here</a> on why standardized measures such as partial eta-squared are problematic:</p>
<blockquote>
<p>The fact that calculating a global measure of model fit (such as R2) is already riddled with complications and that no simple single number can be found, should be a hint that doing so for a subset of the model parameters (i.e., main-effects or interactions) is even more difficult. Given this, I would not recommend to try finding a measure of standardized effect sizes for mixed models.</p>
</blockquote>
<p>He even gives suggested wording for responding to reviewers who want standardized measures!</p></li>
</ul>
<h2 id="do-i-have-to-specify-the-levels-of-fixed-effects-in-lmer">Do I have to specify the levels of fixed effects in lmer?</h2>
<p>No. See Doug Bates reply to this question <a href="http://r.789695.n4.nabble.com/lme4-and-Variable-level-detection-td881680.html">here</a></p>
<h1 id="miscellaneousprocedural">Miscellaneous/procedural</h1>
<h2 id="pronunciation-of-lmerglmeretc.">Pronunciation of <code>lmer</code>/<code>glmer</code>/etc.</h2>
<ul>
<li><code>lmer</code>: I have heard “ell emm ee arr” (i.e. pronouncing each letter); “elmer” (probably most common); and “lemur”</li>
<li><code>glmer</code>: “gee ell emm ee arr”, “gee elmer”, “glimmer”, or “gleamer”</li>
<li>for <code>lme</code> and <code>nlme</code> people just seem to spell out the names (rather than saying e.g. “lemmy” and “nelmy”)</li>
</ul>
<h2 id="storing-information">Storing information</h2>
<p>Recent versions of <code>lme4</code> output contain an <code>@optinfo</code> slot that stores warnings.</p>
<p>Copied from <a href="https://stat.ethz.ch/pipermail/r-help/2012-February/302767.html" class="uri">https://stat.ethz.ch/pipermail/r-help/2012-February/302767.html</a> :</p>
<blockquote>
<p>There’s a somewhat hack-ish solution, which is to use options(warn=2) to ‘upgrade’ warnings to errors, and then use try() or tryCatch() to catch them.</p>
</blockquote>
<blockquote>
<p>More fancily, I used code that looked something like this to save warnings as I went along (sorry about the &lt;&lt;- ) in a recent simulation study. You could also check w$message to do different things in the case of different warnings.</p>
</blockquote>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'>## n.b. have to set up a 3D warn array first ...</span>
<span class='fu'><a href='https://rdrr.io/r/base/conditions.html'>withCallingHandlers</a></span><span class='op'>(</span><span class='kw'><a href='https://rdrr.io/r/base/conditions.html'>tryCatch</a></span><span class='op'>(</span><span class='fu'>fun</span><span class='op'>(</span>n<span class='op'>=</span><span class='va'>nvec</span><span class='op'>[</span><span class='va'>j</span><span class='op'>]</span>,tau<span class='op'>=</span><span class='va'>tauvec</span><span class='op'>[</span><span class='va'>i</span><span class='op'>]</span>,<span class='va'>...</span><span class='op'>)</span>,
                error <span class='op'>=</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>e</span><span class='op'>)</span> <span class='op'>{</span>
                  <span class='va'>warn</span><span class='op'>[</span><span class='va'>k</span>,<span class='va'>i</span>,<span class='va'>j</span><span class='op'>]</span> <span class='op'>&lt;&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/paste.html'>paste</a></span><span class='op'>(</span><span class='st'>"ERROR:"</span>,<span class='va'>e</span><span class='op'>$</span><span class='va'>message</span><span class='op'>)</span>
              <span class='va'>NA_ans</span><span class='op'>}</span><span class='op'>)</span>,
               warning <span class='op'>=</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>w</span><span class='op'>)</span> <span class='op'>{</span>
                  <span class='va'>warn</span><span class='op'>[</span><span class='va'>k</span>,<span class='va'>i</span>,<span class='va'>j</span><span class='op'>]</span> <span class='op'>&lt;&lt;-</span> <span class='va'>w</span><span class='op'>$</span><span class='va'>message</span>
                  <span class='fu'><a href='https://rdrr.io/r/base/conditions.html'>invokeRestart</a></span><span class='op'>(</span><span class='st'>"muffleWarning"</span><span class='op'>)</span>
             <span class='op'>}</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<h1 id="mixed-modeling-packages">Mixed modeling packages</h1>
<ul>
<li>also see the <a href="http://glmm.wikidot.com/pkg-comparison">package comparison</a> on <code>glmm.wikidot.com</code></li>
</ul>
<h2 id="which-r-packages-functions-fit-glmms">Which R packages (functions) fit GLMMs?</h2>
<ul>
<li>MASS::glmmPQL (penalized quasi-likelihood)</li>
<li>lme4::glmer (Laplace approximation and adaptive Gauss-Hermite quadrature [AGHQ])</li>
<li>MCMCglmm (Markov chain Monte Carlo)</li>
<li>glmmML (AGHQ)</li>
<li>glmmAK (AGHQ?)</li>
<li>glmmADMB (Laplace)</li>
<li>glmm (from Jim Lindsey’s <code>repeated</code> package: AGHQ)</li>
<li>gamlss.mx</li>
<li>ASREML-R</li>
<li>sabreR</li>
</ul>
<h2 id="should-i-use-aov-nlme-or-lme4-or-some-other-package">Should I use <code>aov()</code>, <code>nlme</code>, or <code>lme4</code>, or some other package?</h2>
<ul>
<li><code>aov()</code> (in the <code>stats</code> package in base R: balanced, orthogonal designs only (R analogue of SAS PROC GLM)</li>
<li><code>nlme</code> (analogue of SAS <code>PROC MIXED</code>/<code>NLMIXED</code>)
<ul>
<li>allows more complex designs than <code>aov</code> (unbalanced, heteroscedasticity and/or correlation among residual errors)</li>
<li>more mature than <code>lme4</code></li>
<li>well-documented <span class="citation" data-cites="pinheiro_mixed-effects_2000">[@pinheiro_mixed-effects_2000]</span></li>
<li>implements R-side effects (heteroscedasticity and correlation)</li>
<li>estimates “denominator degrees of freedom” for <span class="math inline">\(F\)</span> statistics, and hence <span class="math inline">\(p\)</span> values, for LMMs (but see above)</li>
</ul></li>
<li><code>lme4</code> (also SAS <code>PROC MIXED</code>/<code>NLMIXED</code>):
<ul>
<li>fastest</li>
<li>best for crossed designs (although they are possible in <code>lme</code>)</li>
<li>GLMMs</li>
<li>cutting-edge (for better or worse!)</li>
<li>likelihood profiles</li>
<li>use <code>lme4</code> for GLMMs, or if you have big data (thousands to tens of thousands of records)</li>
</ul></li>
</ul>
<p>The following is modified from a contribution by Kingsford Jones, found 2010-03-16</p>
<h3 id="linear-and-nonlinear-mixed-models">linear and nonlinear mixed models</h3>
<ul>
<li><a href="http://cran.r-project.org/web/packages/lme4/index.html">lme</a> – Linear mixed-effects models using S4 classes</li>
<li><code>lmm</code> – Linear mixed models</li>
<li><code>nlme</code> – Linear and Nonlinear Mixed Effects Models</li>
<li><code>sabreR</code></li>
<li><a href="http://cran.r-project.org/web/packages/regress/index.html">regress</a> Linear mixed models</li>
</ul>
<h3 id="glmms">GLMMs</h3>
<ul>
<li>glmmAK – Generalized Linear Mixed Models</li>
<li>MASS – Main Package of Venables and Ripley’s MASS (see function glmmPQL)</li>
<li>MCMCglmm – MCMC Generalised Linear Mixed Models</li>
<li>lme4 (glmer)</li>
<li>glmmML</li>
<li>gamlss.mx</li>
<li>sabreR</li>
</ul>
<h3 id="additive-and-generalized-additive-mixed-models">Additive and generalized-additive mixed models</h3>
<ul>
<li>amer – Additive mixed models with lme4</li>
<li>gamm4 – Generalized additive mixed models using mgcv and lme4</li>
<li>mgcv (gamm function, via glmmPQL in MASS package)</li>
<li>gamlss.mx</li>
</ul>
<h3 id="hierarchical-glms">Hierarchical GLMs</h3>
<ul>
<li>hglm – hglm is used to fit hierarchical generalized linear models</li>
<li>HGLMMM – Hierarchical Generalized Linear Models</li>
</ul>
<h3 id="diagnostic-and-modeling-frameworks">diagnostic and modeling frameworks</h3>
<ul>
<li>influence.ME – Tools for detecting influential data in mixed effects models</li>
<li>arm – Data Analysis Using Regression and Multilevel/Hierarchical Models</li>
<li>pamm – Power analysis for random effects in mixed models</li>
<li>RLRsim – Exact (Restricted) Likelihood Ratio tests for mixed and additive models</li>
<li>npde – Normalised prediction distribution errors for nonlinear mixed-effect models</li>
<li>multilevel – Multilevel Functions (psychology-oriented; within-group agreement, random group resampling, etc.)</li>
<li>languageR</li>
<li>pbkrtest – parametric bootstrap and Kenward-Roger tests</li>
</ul>
<h3 id="data-and-examples">data and examples</h3>
<ul>
<li>MEMSS – Data sets from Mixed-effects Models in S</li>
<li>mlmRev – Examples from Multilevel Modelling Software Review</li>
<li>SASmixed – Data sets from “SAS System for Mixed Models”</li>
</ul>
<h3 id="extensions">extensions</h3>
<ul>
<li>lmeSplines – lmeSplines</li>
<li>lmec – Linear Mixed-Effects Models with Censored Responses</li>
<li>kinship – mixed-effects Cox models, sparse matrices, and modeling data from large pedigrees</li>
<li>coxme – Mixed Effects Cox Models</li>
<li>ordinal – Regression Models for Ordinal Data</li>
<li>phmm – Proportional Hazards Mixed-effects Model (PHMM)</li>
<li>pedigreemm – Pedigree-based mixed-effects models</li>
<li>(see also MCMCglmm for pedigree-based approaches)</li>
<li>heavy – Estimation in the linear mixed model using heavy-tailed distributions</li>
<li>GLMMarp – Generalized Linear Multilevel Model with AR(p) Errors Package</li>
<li>glmmlasso – penalized GLMM fitting</li>
<li>spatialCovariance – spatial covariance matrix calculations</li>
</ul>
<h3 id="interfaces-to-other-systems">Interfaces to other systems</h3>
<ul>
<li>glmmBUGS – Generalised Linear Mixed Models and Spatial Models with BUGS</li>
<li>Interfaces to WinBUGS/OpenBUGS/JAGS (roll your own model file):</li>
<li>R2WinBUGS</li>
<li>r2jags</li>
<li>rjags</li>
<li>RBugs</li>
</ul>
<h3 id="modeling-based-on-lmms">modeling based on LMMs</h3>
<ul>
<li><code>nlmeODE</code> – Non-linear mixed-effects modelling in nlme using differential equations</li>
<li><code>longRPart</code> – Recursive partitioning of longitudinal data using mixed-effects models</li>
<li><code>PSM</code> – Non-Linear Mixed-Effects modelling using Stochastic Differential Equations</li>
</ul>
<h2 id="off-cran-mixed-modeling-packages">Off-CRAN mixed modeling packages:</h2>
<h3 id="r-forge-and-github">R-forge and Github:</h3>
<ul>
<li><code>glmmADMB</code> (R-forge, interface to AD Model Builder)</li>
<li><code>spida</code>, <code>p3d</code> (Georges Monette)</li>
</ul>
<h3 id="other-open-source">Other open source:</h3>
<ul>
<li><a href="http://www.stat.umn.edu/geyer/bernor/%20bernor">bernor</a> package (logit-normal fitting), by Yun Ju Sung and Charles J. Geyer</li>
<li><code>glmm</code> (in Jim Lindsey’s <code>repeated</code> package: at <a href="http://www.commanster.eu/rcode.html">Lindsey’s web site</a></li>
</ul>
<h3 id="commercial">Commercial:</h3>
<ul>
<li><code>OpenMx</code> – Advanced Structural Equation Modeling</li>
<li><code>ASReml-R</code> (commercial, but 30 days’ free use/free license for academic or developing-country use available). Very good at complex LMMs (fast, flexible covariance structures, etc.), but only offers PQL for GLMMs, and the manual says: &gt; we cannot recommend the use of this technique for general use. It is included in the current version of asreml() for advanced users. It is highly recommended that its use be accompanied by some form of cross-validatory assessment for the specific dataset concerned." Resources:</li>
<li><a href="http://rwiki.sciviews.org/doku.php?id=guides:tutorials:asreml">short R wiki tutorial</a></li>
<li><a href="http://www.vsni.co.uk/downloads/asreml/release3/asreml-R.pdf%20reference%20manual">reference manual</a> (PDF)</li>
<li>Luis Apiolaza’s <a href="http://apiolaza.net/asreml-r/">asreml-r cookbook</a></li>
</ul>
<h2 id="package-versions-used">Package versions used</h2>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/utils/sessionInfo.html'>sessionInfo</a></span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>R version 4.0.2 (2020-06-22)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 19042)

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252 
[2] LC_CTYPE=English_United States.1252   
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C                          
[5] LC_TIME=English_United States.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods  
[7] base     

other attached packages:
 [1] ggplot2_3.3.3      RLRsim_3.1-6       nlme_3.1-148      
 [4] dplyr_1.0.3        broom.mixed_0.2.6  glmmTMB_1.0.2.1   
 [7] equatiomatic_0.2.0 lme4_1.1-26        Matrix_1.2-18     
[10] Cairo_1.5-12.2     pander_0.6.3       knitr_1.31        

loaded via a namespace (and not attached):
 [1] Rcpp_1.0.6        mvtnorm_1.1-1     lattice_0.20-41  
 [4] tidyr_1.1.2       zoo_1.8-8         assertthat_0.2.1 
 [7] digest_0.6.27     utf8_1.1.4        R6_2.5.0         
[10] plyr_1.8.6        backports_1.2.1   evaluate_0.14    
[13] coda_0.19-4       highr_0.8         pillar_1.5.1     
[16] rlang_0.4.10      multcomp_1.4-15   minqa_1.2.4      
[19] rstudioapi_0.13   nloptr_1.2.2.2    jquerylib_0.1.3  
[22] rmarkdown_2.7     labeling_0.4.2    splines_4.0.2    
[25] statmod_1.4.35    stringr_1.4.0     TMB_1.7.18       
[28] munsell_0.5.0     broom_0.7.5       compiler_4.0.2   
[31] xfun_0.20         pkgconfig_2.0.3   mgcv_1.8-31      
[34] htmltools_0.5.1.1 downlit_0.2.1     tidyselect_1.1.0 
[37] tibble_3.1.0      codetools_0.2-16  fansi_0.4.2      
[40] withr_2.4.0       crayon_1.3.4      MASS_7.3-53.1    
[43] grid_4.0.2        gtable_0.3.0      jsonlite_1.7.2   
[46] xtable_1.8-4      lifecycle_0.2.0   DBI_1.1.1        
[49] magrittr_2.0.1    scales_1.1.1      estimability_1.3 
[52] cli_2.2.0         stringi_1.5.3     farver_2.0.3     
[55] reshape2_1.4.4    bslib_0.2.4       ellipsis_0.3.1   
[58] generics_0.1.0    vctrs_0.3.6       boot_1.3-25      
[61] sandwich_3.0-0    distill_1.2       TH.data_1.0-10   
[64] tools_4.0.2       glue_1.4.2        purrr_0.3.4      
[67] emmeans_1.5.3     survival_3.1-12   yaml_2.2.1       
[70] colorspace_2.0-0  sass_0.3.1       </code></pre>
</div>
<h2 id="to-do">To do</h2>
<ul>
<li>add links to <code>merDeriv</code> for standard devs of variances, robust estimates. More on Rizopoulos package</li>
<li>update package descriptions; cross-link with <a href="http://bbolker.github.io/mixedmodels-misc/MixedModels.html">Task View</a> ? <code>rethinking</code>, <code>brms</code>, …</li>
<li>more on post-analysis (<code>broom(.mixed)</code>, <code>emmeans</code>, <code>multcomp</code>, …)</li>
<li>more on confidence intervals, simulating from conditional distributions, etc.)</li>
</ul>
<h1 id="credited-to">Credited to:</h1>
<p>This is original work by Ben Bolker and colleagues, kindly credit them if you find this useful. Original post at <a href="https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#" class="uri">https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#</a></p>
<p>Distill is a publication format for scientific and technical writing, native to the web.</p>
<p>Learn more about using Distill at <a href="https://rstudio.github.io/distill" class="uri">https://rstudio.github.io/distill</a>.</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r distill-force-highlighting-css"><code class="sourceCode r"></code></pre></div>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>in R, <code>foo::bar</code> (or <code>foo::bar()</code>) denotes “function <code>bar</code> in package <code>foo</code>”).<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>the dispersion factor is estimated on a variance, so we need to take the square root to apply it to the standard error<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
<!--radix_placeholder_article_footer-->
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom"></div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
